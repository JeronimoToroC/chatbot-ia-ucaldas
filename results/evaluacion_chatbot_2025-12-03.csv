ID,Categoria,Nivel,Pregunta,Respuesta_Esperada,Respuesta_Obtenida,Fuentes,Num_Fuentes,No_Tiene_Info,Exactitud,Cobertura,Claridad,Citas,Alucinacion,Seguridad,Score_R,Timestamp
Q001,conceptos_basicos,basico,"¿Qué es la Inteligencia Artificial?","Campo de la informática que desarrolla sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como aprendizaje, razonamiento y resolución de problemas.","La Inteligencia Artificial (IA) es un campo de la informática que se enfoca en el desarrollo de sistemas y tecnologías capaces de realizar tareas que normalmente requieren inteligencia humana. Estos sistemas pueden aprender, razonar, planificar, percibir el entorno, reconocer patrones y tomar decisiones de manera autónoma. La IA se basa en algoritmos y modelos matemáticos que permiten a las máquinas simular procesos cognitivos humanos.  En términos más simples, la IA busca emular la inteligencia","Universidad de Caldas - Departamento de Ingeniería de Sistemas y Computación",1,false,0.467,0.533,1,1,0,1,0.57,2025-12-03T02:22:44.634Z
Q002,conceptos_basicos,intermedio,"¿Cuál es la diferencia entre IA débil e IA fuerte?","IA débil (narrow AI) está diseñada para tareas específicas, mientras que IA fuerte (general AI) tendría capacidades cognitivas generales comparables a las humanas.","La diferencia entre la inteligencia artificial débil y la inteligencia artificial fuerte radica en su capacidad para simular la inteligencia humana de manera general. La inteligencia artificial débil se refiere a sistemas diseñados para realizar tareas específicas de manera eficiente, sin poseer una comprensión o conciencia real. Por otro lado, la inteligencia artificial fuerte se refiere a sistemas capaces de comprender, aprender y razonar de manera similar a los seres humanos, lo que implica u","",0,true,0.143,1,0.85,0,0.5,1,0.278,2025-12-03T02:22:44.634Z
Q003,historia,basico,"¿Quién acuñó el término Inteligencia Artificial y en qué año?","John McCarthy acuñó el término en 1956 durante la Conferencia de Dartmouth.","No tengo información suficiente en mi base de conocimientos para responder esta pregunta con precisión.","",0,true,0.1,0,0.7,1,0,1,0.29,2025-12-03T02:22:44.634Z
Q004,historia,intermedio,"¿Qué fue el invierno de la IA?","Períodos (principalmente años 70s y finales 80s) de reducción drástica en financiamiento e interés en IA debido a expectativas no cumplidas y limitaciones técnicas.","El ""invierno de la IA"" se refiere a períodos en la historia de la inteligencia artificial en los que hubo un declive significativo en el interés, la financiación y el progreso en el campo de la IA. El término se originó a partir de dos períodos anteriores de desilusión con la IA, uno en la década de 1970 y otro en la década de 1980, cuando las expectativas iniciales sobre el potencial de la inteligencia artificial no se cumplieron y se produjo un retroceso en la investigación y el desarrollo e","Historia de la inteligencia artificial - Universidad de Caldas, El invierno de la inteligencia artificial - Documento de investigación",2,false,0.25,1,1,1,0,1,0.587,2025-12-03T02:22:44.634Z
Q005,ml_clasico,intermedio,"¿Qué es un árbol de decisión en Machine Learning?","Modelo de aprendizaje supervisado que toma decisiones mediante una estructura de árbol donde cada nodo representa una prueba sobre un atributo y las hojas representan las decisiones finales.","Un árbol de decisión en Machine Learning es un modelo predictivo que se utiliza para representar y tomar decisiones basadas en una secuencia de reglas lógicas. Se compone de nodos que representan condiciones o preguntas sobre las características de los datos, y de ramas que representan las posibles respuestas a esas preguntas. Al seguir el camino desde el nodo raíz hasta las hojas, se puede llegar a una decisión o predicción sobre un determinado valor objetivo.  En un árbol de decisión, cada nod","machine_learning_book.pdf",1,false,0.475,1,1,1,0,1,0.666,2025-12-03T02:22:44.634Z
Q006,ml_clasico,avanzado,"¿Cómo funciona el algoritmo de Support Vector Machine (SVM)?","SVM encuentra el hiperplano óptimo que maximiza el margen entre clases en un espacio de características, pudiendo usar kernels para clasificación no lineal.","El algoritmo de Support Vector Machine (SVM) es un método de aprendizaje supervisado utilizado para clasificación y regresión. Su funcionamiento se basa en encontrar el hiperplano óptimo que mejor separa las clases en un espacio de características de alta dimensión. El objetivo es encontrar el hiperplano que maximiza el margen entre las clases, es decir, la distancia entre el hiperplano y los puntos más cercanos de cada clase, conocidos como vectores de soporte.  En SVM, se busca un hiperplano d","",0,true,0.969,1,1,0.3,0.5,1,0.649,2025-12-03T02:22:44.634Z
Q007,deep_learning_llms,intermedio,"¿Qué es un transformer en el contexto de deep learning?","Arquitectura de red neuronal basada en mecanismos de atención que procesa secuencias en paralelo, base de modelos como GPT y BERT.","En el contexto de deep learning, un Transformer es un modelo de red neuronal que se ha vuelto muy popular en tareas de procesamiento del lenguaje natural (NLP). Fue introducido por Vaswani et al. en 2017 y se destaca por su capacidad para capturar relaciones de largo alcance en secuencias de datos, sin depender de estructuras recurrentes o convolucionales.  El Transformer se basa en un mecanismo de atención que permite a la red enfocarse en diferentes partes de la entrada durante el proceso de a","",0,true,0.867,1,1,0.3,0.5,1,0.613,2025-12-03T02:22:44.635Z
Q008,deep_learning_llms,avanzado,"¿Qué es el fine-tuning en Large Language Models?","Proceso de ajustar un modelo preentrenado con datos específicos de una tarea o dominio para mejorar su desempeño en aplicaciones particulares.","El fine-tuning en Large Language Models se refiere a un proceso en el que un modelo pre-entrenado, como GPT-3 de OpenAI o BERT de Google, se ajusta o adapta a una tarea específica o dominio de datos particulares. Estos modelos pre-entrenados son entrenados en grandes cantidades de datos textuales genéricos para aprender representaciones lingüísticas generales. Sin embargo, para tareas específicas como traducción, resumen de texto o análisis de sentimientos, es necesario adaptar el modelo pre-ent","OpenAI Blog - Fine-Tuning in Large-Scale Language Models",1,false,0.6,1,0.9,1,0,1,0.695,2025-12-03T02:22:44.635Z
Q009,etica_regulacion,intermedio,"¿Qué es el AI Act de la Unión Europea?","Marco regulatorio que clasifica sistemas de IA según riesgo y establece requisitos de transparencia, seguridad y derechos fundamentales.","El AI Act es una propuesta de regulación de la Unión Europea para el uso de la inteligencia artificial en la sociedad. Se trata de un marco legislativo que busca establecer normas claras y éticas para el desarrollo y despliegue de sistemas de inteligencia artificial en la región.  El objetivo principal del AI Act es garantizar la seguridad y los derechos de los ciudadanos europeos en el contexto de la IA. Este acto propone una serie de requisitos y obligaciones para los desarrolladores y usuario","Documento oficial de la Unión Europea sobre el AI Act",1,false,0.9,1,1,1,0,1,0.815,2025-12-03T02:22:44.635Z
Q010,aplicaciones,basico,"¿Cuáles son tres aplicaciones comunes de IA en la vida cotidiana?","Asistentes virtuales (Siri, Alexa), sistemas de recomendación (Netflix, Spotify) y reconocimiento facial en smartphones.","Tres aplicaciones comunes de la Inteligencia Artificial en la vida cotidiana son:  1. **Asistentes de voz y chatbots**: Los asistentes virtuales como Siri, Alexa, Google Assistant y chatbots en sitios web utilizan IA para comprender y responder a las consultas de los usuarios. Estos sistemas emplean procesamiento del lenguaje natural y aprendizaje automático para interpretar el lenguaje humano y proporcionar respuestas útiles.  2. **Recomendaciones personalizadas**: Plataformas como Netflix, Spo","",0,true,0.632,0.825,0.85,0,0.5,1,0.414,2025-12-03T02:22:44.635Z
Q011,conceptos_basicos,basico,"¿Qué se entiende por inteligencia artificial en el contexto computacional?","Es el campo de estudio que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana. Incluye técnicas para percibir, razonar, aprender y tomar decisiones basadas en datos.","En el contexto computacional, la inteligencia artificial (IA) se refiere a la capacidad de las máquinas o sistemas informáticos para realizar tareas que normalmente requieren inteligencia humana. La IA implica el desarrollo de algoritmos y modelos que permiten a las máquinas aprender de los datos, adaptarse a nuevas situaciones y realizar decisiones o acciones de manera autónoma.  La IA se basa en la simulación de procesos cognitivos humanos, como el razonamiento, el aprendizaje, la percepción, ","",0,true,0.679,0.767,0.85,0,0.5,1,0.418,2025-12-03T02:22:44.635Z
Q012,historia,intermedio,"¿Cuál fue el impacto de la Conferencia de Dartmouth en el desarrollo de la IA?","La Conferencia de Dartmouth de 1956 marcó el inicio formal de la IA como disciplina académica. Reunió a investigadores clave y estableció una agenda para explorar máquinas capaces de simular la inteligencia humana.","La Conferencia de Dartmouth, celebrada en 1956, es considerada como el punto de partida del campo de la Inteligencia Artificial (IA). El impacto de esta conferencia fue significativo en el desarrollo y la consolidación de la IA como disciplina académica y de investigación. En la conferencia, se sentaron las bases teóricas y conceptuales de la IA, se establecieron objetivos y se delinearon posibles enfoques para la creación de programas de computadora que pudieran simular la inteligencia humana. ","Documento sobre historia de la IA",1,false,0.778,1,1,1,0,1,0.772,2025-12-03T02:22:44.636Z
Q013,ml_clasico,intermedio,"¿En qué consiste la regresión logística y para qué tipo de problemas se utiliza?","La regresión logística es un modelo estadístico que estima la probabilidad de pertenencia a una clase binaria usando una función sigmoide. Se emplea ampliamente en tareas de clasificación como detección de spam o diagnóstico médico.","La regresión logística es un algoritmo de aprendizaje supervisado utilizado para la clasificación de datos. A pesar de su nombre, la regresión logística se utiliza para problemas de clasificación, no de regresión. Su objetivo es predecir la probabilidad de que una observación pertenezca a una determinada categoría o clase.  En la regresión logística, se aplica una función logística a una combinación lineal de las variables de entrada. Esta función logística transforma la salida a un valor entre ","",0,true,0.639,1,0.85,0,0.5,1,0.451,2025-12-03T02:22:44.636Z
Q014,deep_learning_llms,intermedio,"¿Qué ventaja principal introdujo la arquitectura Transformer en comparación con las redes recurrentes?","Los Transformers permiten procesar secuencias completas en paralelo mediante mecanismos de atención, eliminando la dependencia estricta del orden secuencial. Esto mejora la eficiencia computacional y capta mejor relaciones de largo alcance.","La arquitectura Transformer introdujo una ventaja principal significativa en comparación con las redes recurrentes, y es la capacidad de procesar secuencias de datos de manera más eficiente y paralela. Mientras que las redes recurrentes procesan la información de manera secuencial, lo que puede llevar a problemas con la dependencia a largo plazo y al aumento del tiempo de entrenamiento, los Transformers utilizan mecanismos de atención para procesar todas las posiciones de la secuencia de entrada","doc_004_AI_Cognitive_Models.pdf",1,false,0.668,1,1,1,0,1,0.734,2025-12-03T02:22:44.636Z
Q015,etica_regulacion,avanzado,"¿Por qué el sesgo algorítmico es un riesgo crítico en sistemas de IA utilizados para decisiones públicas?","El sesgo algorítmico puede amplificar desigualdades existentes cuando se usan datos históricos no representativos o discriminatorios. En decisiones públicas, esto afecta la equidad y puede vulnerar derechos fundamentales.","El sesgo algorítmico es un riesgo crítico en sistemas de IA utilizados para decisiones públicas debido a su capacidad para perpetuar y amplificar sesgos existentes en los datos utilizados para entrenar los modelos. Este sesgo puede llevar a decisiones discriminatorias y perjudiciales para ciertos grupos de la población, lo que socava la equidad y la justicia en las decisiones públicas.   Por ejemplo, si un sistema de IA utilizado para la concesión de préstamos se entrena con datos históricos que","",0,true,0.895,1,0.65,0,0.5,1,0.511,2025-12-03T02:22:44.636Z
Q016,aplicaciones,basico,"¿Cómo se utiliza la IA en los sistemas de recomendación?","Estos sistemas analizan patrones de comportamiento y preferencias del usuario para sugerir contenidos relevantes. Emplean técnicas de filtrado colaborativo y modelos predictivos para mejorar la personalización.","Los sistemas de recomendación son una aplicación común de la Inteligencia Artificial (IA) que utiliza algoritmos para predecir y sugerir elementos de interés para los usuarios. La IA se utiliza en los sistemas de recomendación para analizar grandes cantidades de datos y proporcionar recomendaciones personalizadas a los usuarios.   En primer lugar, la IA en los sistemas de recomendación recopila datos sobre las preferencias, comportamientos y patrones de los usuarios. Estos datos pueden incluir h","Documento sobre sistemas de recomendación en IA",1,false,0.65,1,0.9,1,0,1,0.712,2025-12-03T02:22:44.637Z
Q017,conceptos_basicos,intermedio,"¿Qué diferencia al aprendizaje supervisado del no supervisado?","El aprendizaje supervisado utiliza datos etiquetados para entrenar modelos que predicen valores o clases específicas. El no supervisado busca patrones o estructuras ocultas en datos sin etiquetar, como agrupamientos.","El aprendizaje supervisado y el aprendizaje no supervisado son dos enfoques fundamentales en el campo del machine learning que se utilizan para entrenar modelos y extraer información de los datos, pero difieren en la forma en que se lleva a cabo el proceso de aprendizaje.  En el aprendizaje supervisado, los datos de entrenamiento están etiquetados, es decir, cada ejemplo de entrada tiene una etiqueta que indica la salida deseada. El objetivo es que el modelo aprenda a mapear las entradas a las s","Introducción al Machine Learning - Universidad de Caldas",1,false,0.853,0.65,1,1,0,1,0.728,2025-12-03T02:22:44.637Z
Q018,ml_clasico,avanzado,"¿Qué papel juega el margen en los modelos SVM y por qué es relevante?","El margen es la distancia entre el hiperplano de separación y los puntos más cercanos de cada clase. Maximizarlo mejora la capacidad de generalización y reduce la sensibilidad al ruido del modelo.","En los modelos de Máquinas de Vectores de Soporte (SVM), el margen se refiere a la distancia entre el hiperplano de separación y los puntos de datos más cercanos de cada clase. El objetivo principal de SVM es encontrar el hiperplano que maximice este margen, lo que se conoce como el margen máximo. Este margen es crucial en los modelos SVM por varias razones.  El margen máximo en SVM ayuda a mejorar la capacidad de generalización del modelo al reducir el riesgo de sobreajuste. Al maximizar la dis","",0,true,0.925,1,0.9,0.3,0.5,1,0.619,2025-12-03T02:22:44.637Z
Q019,deep_learning_llms,avanzado,"¿Por qué los modelos de lenguaje a gran escala pueden presentar alucinaciones en sus respuestas?","Estas alucinaciones surgen cuando el modelo genera información plausible pero incorrecta debido a patrones estadísticos aprendidos sin comprensión semántica real. También se relacionan con datos incompletos, sesgos y la naturaleza probabilística de la generación.","Los modelos de lenguaje a gran escala, como los basados en redes neuronales, pueden presentar alucinaciones en sus respuestas debido a la complejidad y la naturaleza probabilística de su funcionamiento. Estos modelos aprenden patrones lingüísticos a partir de grandes cantidades de datos textuales, lo que les permite generar respuestas coherentes en muchos casos. Sin embargo, debido a la enorme cantidad de parámetros y la complejidad de las interacciones entre ellos, los modelos pueden generar re","",0,true,0.693,1,0.85,0,0.5,1,0.47,2025-12-03T02:22:44.637Z
Q020,aplicaciones,intermedio,"¿Cómo puede la IA apoyar el diagnóstico médico asistido?","Los modelos de IA analizan imágenes, registros clínicos y patrones de síntomas para ayudar a identificar posibles enfermedades. Funcionan como herramientas de apoyo que aumentan la precisión y rapidez del diagnóstico, pero no sustituyen el criterio clínico.","La Inteligencia Artificial (IA) puede apoyar el diagnóstico médico asistido de diversas maneras. Una de las aplicaciones más destacadas es en el campo de la imagen médica, donde la IA puede analizar imágenes de resonancia magnética (MRI) y tomografía por emisión de positrones (PET) para ayudar en el diagnóstico de enfermedades como el Alzheimer. Los sistemas de apoyo a la decisión basados en IA pueden aprender de estas imágenes para mejorar el rendimiento diagnóstico, reducir errores médicos y b","",0,true,0.771,0.767,0.85,0,0.5,1,0.451,2025-12-03T02:22:44.637Z
Q021,conceptos_basicos,basico,"¿Qué es un agente inteligente en IA?","Es una entidad que percibe su entorno mediante sensores y actúa sobre él mediante actuadores. Su objetivo es seleccionar acciones que maximicen su desempeño según una medida definida.","Un agente inteligente en Inteligencia Artificial (IA) es un sistema computacional que percibe su entorno y actúa de manera autónoma para lograr objetivos específicos. Estos agentes pueden ser programas de software, robots físicos o cualquier otro dispositivo que interactúe con su entorno para llevar a cabo tareas de manera inteligente. Un agente inteligente está diseñado para tomar decisiones basadas en la información que recibe del entorno y en función de sus objetivos predefinidos.  Existen di","",0,true,0.568,1,1,0.3,0.5,1,0.509,2025-12-03T02:22:44.637Z
Q022,historia,intermedio,"¿Qué aportó Alan Turing al desarrollo de la inteligencia artificial?","Turing propuso el modelo computacional que fundamenta el concepto de algoritmo y la idea de una máquina universal. También formuló la Prueba de Turing como criterio para evaluar el comportamiento inteligente en máquinas.","Alan Turing realizó importantes contribuciones al desarrollo de la inteligencia artificial. Una de sus contribuciones más destacadas fue la creación de lo que se conoce como la ""Prueba de Turing"", también conocida como la ""Prueba de Turing de la Inteligencia"". Esta prueba propuesta por Turing en 1950 consiste en evaluar la capacidad de una máquina para exhibir un comportamiento inteligente equivalente o indistinguible del de un ser humano. La idea detrás de esta prueba es determinar si una m",""Alan Turing's Legacy: Artificial Intelligence", www.turing.org.uk",1,false,0.567,1,0.8,1,0,1,0.668,2025-12-03T02:22:44.637Z
Q023,ml_clasico,basico,"¿Qué es un árbol de decisión y para qué se utiliza?","Es un modelo que divide iterativamente el espacio de datos mediante reglas simples para realizar clasificación o regresión. Su estructura jerárquica facilita la interpretación y el análisis de decisiones.","Un árbol de decisión es un modelo de aprendizaje supervisado en el campo de la inteligencia artificial y el machine learning. Se utiliza para tomar decisiones basadas en múltiples condiciones o características. Este modelo se representa de manera jerárquica en forma de árbol, donde cada nodo interno representa una característica o atributo, cada rama representa una decisión basada en esa característica, y cada hoja representa el resultado de la decisión.  Los árboles de decisión son ampliamente ","",0,true,0.615,1,0.85,0,0.5,1,0.443,2025-12-03T02:22:44.637Z
Q024,deep_learning_llms,intermedio,"¿Qué papel cumplen las funciones de activación en una red neuronal profunda?","Permiten introducir no linealidad en las capas, lo que habilita a la red para aprender representaciones complejas. Activaciones como ReLU o tanh ayudan a controlar gradientes y mejorar la estabilidad del entrenamiento.","Las funciones de activación desempeñan un papel fundamental en una red neuronal profunda al introducir no linealidades en el modelo, permitiendo a la red aprender y modelar relaciones complejas en los datos. Estas funciones son aplicadas a la salida de cada neurona en una capa de la red y ayudan a determinar si una neurona debe activarse o no en función de la entrada recibida.  En una red neuronal profunda, las funciones de activación son esenciales para permitir que el modelo aprenda de manera ","Documento de investigación sobre redes neuronales profundas",1,false,0.813,1,1,1,0,1,0.785,2025-12-03T02:22:44.637Z
Q025,etica_regulacion,intermedio,"¿Por qué es importante la transparencia en los sistemas de IA?","La transparencia facilita comprender cómo un sistema llega a sus decisiones, lo que mejora la confianza y la rendición de cuentas. Además, permite detectar errores, sesgos y riesgos de impacto social.","La transparencia en los sistemas de Inteligencia Artificial (IA) es fundamental por varias razones. En primer lugar, la transparencia promueve la confianza en los sistemas de IA al permitir que los usuarios comprendan cómo funcionan y por qué toman ciertas decisiones. Esto es crucial, especialmente en aplicaciones críticas como la salud, la justicia o la seguridad, donde es necesario entender el razonamiento detrás de las recomendaciones o acciones de la IA.  Además, la transparencia en los sist",""The importance of transparency in AI" - AI Ethics Lab",1,false,0.567,1,0.9,1,0,0,0.733,2025-12-03T02:22:44.638Z
Q026,aplicaciones,avanzado,"¿Cómo puede la IA optimizar procesos en cadenas de suministro?","Modelos predictivos anticipan demanda, ajustan inventarios y mejoran decisiones logísticas en tiempo real. Esto reduce costos, incrementa eficiencia y permite adaptarse rápidamente a condiciones cambiantes.","La Inteligencia Artificial (IA) puede optimizar procesos en cadenas de suministro de diversas formas. Una de las aplicaciones más comunes es a través de la predicción y la optimización de la demanda. Mediante algoritmos de machine learning, la IA puede analizar datos históricos de ventas, tendencias del mercado, factores estacionales y otros datos relevantes para predecir de manera más precisa la demanda de productos. Esta predicción más precisa ayuda a las empresas a gestionar de manera eficien",""AI in Supply Chain Management: Enhancing Efficiency and Reducing Costs"",1,false,0.789,1,1,1,0,1,0.776,2025-12-03T02:22:44.638Z
Q027,conceptos_basicos,intermedio,"¿Qué es el espacio de búsqueda en un problema de IA?","Es el conjunto de todos los estados posibles que puede adoptar un sistema al intentar resolver una tarea. Definir y explorar eficazmente este espacio es esencial para algoritmos como búsqueda heurística.","El espacio de búsqueda en un problema de Inteligencia Artificial se refiere al conjunto de todos los posibles estados y acciones que un agente puede explorar para encontrar una solución. En términos simples, representa todas las posibles combinaciones de decisiones que pueden llevar a la resolución de un problema.  Por ejemplo, en el caso de un algoritmo de búsqueda en un juego de ajedrez, el espacio de búsqueda sería el conjunto de todas las posibles jugadas que un jugador puede realizar a part","",0,true,0.672,1,0.75,0,0.5,1,0.448,2025-12-03T02:22:44.638Z
Q028,historia,avanzado,"¿Cuál fue la relevancia del perceptrón en los primeros desarrollos del aprendizaje automático?","El perceptrón introdujo un modelo formal para el aprendizaje lineal y despertó un gran entusiasmo inicial por las redes neuronales. Sin embargo, sus limitaciones teóricas llevaron a un estancamiento temporal, que más tarde se superó con técnicas de entrenamiento profundo.","El perceptrón fue fundamental en los primeros desarrollos del aprendizaje automático debido a su importancia en la historia de las redes neuronales y su contribución al campo de la inteligencia artificial. El perceptrón, propuesto por Frank Rosenblatt en 1957, es un algoritmo de aprendizaje supervisado para clasificación binaria que simula el funcionamiento de una neurona en el cerebro humano.   En ese momento, el perceptrón fue considerado un avance significativo en el campo del aprendizaje aut",""Deep Learning" - Goodfellow et al.",1,false,0.577,0.767,0.9,1,0,1,0.64,2025-12-03T02:22:44.639Z
Q029,ml_clasico,intermedio,"¿Para qué se utiliza el algoritmo k-means y cómo funciona a nivel general?","k-means agrupa datos en k clústeres asignando cada punto al centro más cercano y ajustando estos centros iterativamente. Es un método eficiente para revelar estructuras internas en datos no etiquetados.","El algoritmo K-means es una técnica de clustering utilizada en aprendizaje no supervisado para agrupar datos en k grupos distintos. Su objetivo principal es dividir un conjunto de datos en clusters de manera que los puntos dentro de un mismo cluster sean similares entre sí y diferentes de los puntos en otros clusters.  El funcionamiento del algoritmo K-means a nivel general se puede describir en los siguientes pasos: 1. **Inicialización**: Se seleccionan aleatoriamente k centroides iniciales que","",0,true,0.447,1,0.85,0,0.5,1,0.384,2025-12-03T02:22:44.639Z
Q030,deep_learning_llms,avanzado,"¿Qué son los embeddings y por qué son esenciales en el procesamiento del lenguaje natural?","Los embeddings representan palabras o tokens como vectores densos que capturan relaciones semánticas y sintácticas. Permiten a los modelos operar en un espacio continuo donde similitudes lingüísticas pueden aprenderse y explotarse.","Los embeddings en el procesamiento del lenguaje natural son representaciones numéricas de palabras o frases que capturan el significado semántico y la relación entre ellas. Estas representaciones vectoriales permiten a los modelos de procesamiento del lenguaje natural entender el significado de las palabras en un contexto determinado. Los embeddings son esenciales en NLP por varias razones:  En primer lugar, los embeddings ayudan a superar la dimensionalidad y la dispersión de los datos en el pr","Documento sobre Procesamiento del Lenguaje Natural en la Universidad de Caldas",1,false,0.529,1,1,1,0,1,0.685,2025-12-03T02:22:44.639Z
Q031,conceptos_basicos,basico,"¿Qué es un sistema experto en inteligencia artificial?","Es un programa diseñado para imitar la toma de decisiones de un especialista humano en un dominio específico. Utiliza una base de conocimientos y un motor de inferencia para resolver problemas complejos.","Un sistema experto en inteligencia artificial es un tipo de sistema informático diseñado para imitar la capacidad de toma de decisiones de un experto humano en un dominio específico. Estos sistemas utilizan reglas lógicas y bases de conocimiento para resolver problemas complejos y brindar recomendaciones o soluciones.   Los sistemas expertos están compuestos por un motor de inferencia, una base de conocimiento y un mecanismo de adquisición de conocimiento. El motor de inferencia es responsable d","Universidad de Caldas - Departamento de Ingeniería de Sistemas y Computación",1,false,0.72,1,0.9,1,0,1,0.737,2025-12-03T02:22:44.639Z
Q032,historia,intermedio,"¿Qué ocurrió durante el primer 'invierno de la IA'?","El primer invierno de la IA fue un periodo de recortes de financiamiento y desinterés debido a expectativas no cumplidas. Las limitaciones técnicas y el escepticismo frenaron el avance del campo durante varios años.","Durante el primer 'invierno de la IA', hubo un interés significativo en la comunidad de la robótica y la planificación en el desarrollo de algoritmos que pudieran generar comportamientos de agentes interpretables para los humanos. Este interés se centraba en la generación de comportamientos de agentes inteligentes que fueran comprensibles para los observadores humanos a lo largo de la vida de un agente inteligente. La noción de interpretabilidad se refiere a la capacidad de los humanos para ente","",0,true,0.244,1,0.85,0,0.5,1,0.313,2025-12-03T02:22:44.639Z
Q033,ml_clasico,intermedio,"¿Qué es la validación cruzada y por qué se utiliza?","Es una técnica que divide los datos en subconjuntos para entrenar y evaluar un modelo múltiples veces. Permite estimar su desempeño general y reducir el riesgo de sobreajuste.","La validación cruzada es una técnica utilizada en machine learning para evaluar el rendimiento de un modelo predictivo. Consiste en dividir el conjunto de datos en subconjuntos más pequeños, llamados ""folds"", y realizar múltiples iteraciones de entrenamiento y evaluación del modelo en diferentes combinaciones de estos subconjuntos.   Durante cada iteración, un fold se utiliza como conjunto de prueba para evaluar el modelo entrenado con los otros folds como conjunto de entrenamiento. Este proce","",0,true,0.825,1,0.75,0,0.5,1,0.501,2025-12-03T02:22:44.639Z
Q034,deep_learning_llms,intermedio,"¿Cuál es la función del mecanismo de atención en una red neuronal?","El mecanismo de atención permite ponderar la relevancia de distintas partes de una entrada al generar una salida. Esto mejora la capacidad del modelo para capturar dependencias complejas y relaciones a largo plazo.","El mecanismo de atención en una red neuronal es una técnica que permite que la red se enfoque en partes específicas de la entrada durante el proceso de aprendizaje o inferencia. En lugar de procesar toda la entrada de manera uniforme, la atención permite asignar diferentes pesos o niveles de importancia a diferentes partes de los datos de entrada. Esto mejora la capacidad de la red para capturar relaciones complejas y realizar tareas como la traducción automática, la generación de texto y la cla","doc_004_AI_Cognitive_Models.pdf",1,false,0.595,1,1,1,0,1,0.708,2025-12-03T02:22:44.640Z
Q035,etica_regulacion,avanzado,"¿Qué desafíos presenta la responsabilidad legal en sistemas autónomos?","Los sistemas autónomos complican la atribución de responsabilidad cuando ocurren fallos o daños, ya que intervienen múltiples actores. Esto exige marcos regulatorios claros que definan obligaciones y niveles de supervisión.","La responsabilidad legal en sistemas autónomos presenta varios desafíos debido a la complejidad de determinar quién es responsable en caso de daños o errores causados por estas tecnologías. Uno de los principales desafíos es la atribución de responsabilidad, ya que en sistemas autónomos la toma de decisiones puede ser descentralizada y no siempre es posible identificar claramente quién o qué causó el problema. Además, la falta de claridad en la legislación actual sobre cómo responsabilizar a los","Responsible AI: Challenges and Recommendations",1,false,0.42,1,0.9,1,0,1,0.632,2025-12-03T02:22:44.640Z
Q036,aplicaciones,basico,"¿Cómo se aplica la IA en el análisis de imágenes médicas?","La IA detecta patrones en imágenes como radiografías o resonancias para identificar posibles anomalías. Esto ayuda a apoyar diagnósticos tempranos y aumentar la precisión clínica.","La Inteligencia Artificial (IA) se utiliza de diversas formas en el análisis de imágenes médicas para mejorar la precisión, velocidad y eficiencia en el diagnóstico y tratamiento de enfermedades. Una de las aplicaciones más comunes es el uso de algoritmos de aprendizaje profundo, como las redes neuronales convolucionales, para interpretar y analizar imágenes médicas, como radiografías, resonancias magnéticas, tomografías computarizadas, entre otras.  Estos algoritmos pueden identificar patrones ","Documento sobre aplicaciones de IA en imágenes médicas",1,false,0.743,1,0.9,1,0,1,0.745,2025-12-03T02:22:44.640Z
Q037,conceptos_basicos,intermedio,"¿Qué diferencia existe entre un problema determinista y uno estocástico en IA?","En un problema determinista las acciones producen resultados predecibles, mientras que en uno estocástico existe incertidumbre en los efectos de las acciones. Esta diferencia condiciona los métodos de planificación y toma de decisiones.","En el campo de la Inteligencia Artificial (IA), la diferencia fundamental entre un problema determinista y uno estocástico radica en la naturaleza de la incertidumbre presente en el proceso de toma de decisiones.  Un problema determinista en IA es aquel en el que todas las acciones y sus consecuencias están completamente definidas y predecibles. En este tipo de problemas, dada una entrada específica, el resultado siempre será el mismo, sin variabilidad. Por ejemplo, en un juego de ajedrez con re","",0,true,0.732,1,1,0.3,0.7,1,0.546,2025-12-03T02:22:44.640Z
Q038,historia,basico,"¿Quién fue John McCarthy y por qué es importante para la IA?","John McCarthy fue uno de los fundadores de la IA y acuñó el término en 1956. También desarrolló el lenguaje LISP, fundamental para los primeros sistemas de investigación en IA.","John McCarthy fue un destacado científico de la computación y matemático estadounidense, conocido por ser uno de los padres fundadores de la inteligencia artificial. Nacido en 1927, McCarthy es reconocido por sus contribuciones pioneras en el campo de la IA, especialmente por acuñar el término ""inteligencia artificial"" en 1956 durante la Conferencia de Dartmouth, considerada como el punto de partida oficial de la disciplina.  McCarthy es importante para la IA por su papel fundamental en el des",""John McCarthy, Father of Artificial Intelligence, Dies at 84"",1,false,0.855,1,1,1,0,1,0.799,2025-12-03T02:22:44.640Z
Q039,ml_clasico,avanzado,"¿Qué es la regularización L1 y cómo afecta a los modelos?","La regularización L1 agrega una penalización basada en la magnitud absoluta de los coeficientes, promoviendo soluciones dispersas. Esto ayuda a seleccionar características relevantes y reducir el sobreajuste.","La regularización L1, también conocida como regularización de Lasso (Least Absolute Shrinkage and Selection Operator), es una técnica utilizada en machine learning para evitar el sobreajuste de los modelos al penalizar los coeficientes de las características menos importantes, llevándolos a cero. En términos simples, la regularización L1 agrega un término a la función de costo del modelo que es proporcional a la suma de los valores absolutos de los coeficientes de las características.  Al aplica","",0,true,0.625,1,0.65,0,0.5,1,0.416,2025-12-03T02:22:44.640Z
Q040,deep_learning_llms,avanzado,"¿Qué es el fine-tuning en modelos de lenguaje y para qué se utiliza?","El fine-tuning consiste en ajustar un modelo preentrenado usando un conjunto de datos específico para una tarea concreta. Esto permite aprovechar el conocimiento general adquirido y adaptarlo a dominios especializados.","El fine-tuning en modelos de lenguaje se refiere a un proceso en el que un modelo pre-entrenado se ajusta o ""sintoniza"" para adaptarse a una tarea específica o a un conjunto de datos específico. Este enfoque es comúnmente utilizado en el campo del aprendizaje automático y la inteligencia artificial para mejorar el rendimiento de un modelo en una tarea particular sin necesidad de entrenarlo desde cero.  Durante el fine-tuning, un modelo pre-entrenado, como BERT o GPT, se ajusta mediante el entr","",0,true,0.382,1,0.85,0,0.5,1,0.361,2025-12-03T02:22:44.640Z
Q041,conceptos_basicos,basico,"¿Qué es un algoritmo heurístico en IA?","Es un método que utiliza aproximaciones o reglas prácticas para encontrar soluciones satisfactorias cuando una búsqueda exhaustiva es inviable. Las heurísticas permiten acelerar la resolución de problemas complejos sacrificando exactitud perfecta.","Un algoritmo heurístico en Inteligencia Artificial es una técnica de resolución de problemas que se basa en reglas generales o métodos aproximados para encontrar soluciones, en lugar de seguir un proceso determinístico y exacto. Estos algoritmos son utilizados cuando la complejidad de un problema dificulta encontrar una solución óptima en un tiempo razonable.  Los algoritmos heurísticos son especialmente útiles en situaciones donde no es posible aplicar métodos exactos debido a la cantidad de da","",0,true,0.321,1,0.85,0,0.5,1,0.34,2025-12-03T02:22:44.640Z
Q042,historia,intermedio,"¿Por qué el desarrollo de Deep Blue fue relevante en la historia de la IA?","Deep Blue fue el primer sistema en derrotar a un campeón mundial de ajedrez, demostrando la capacidad de las máquinas para superar a expertos humanos en tareas estructuradas. Su éxito impulsó el interés en la IA y la computación de alto rendimiento.","El desarrollo de Deep Blue fue relevante en la historia de la Inteligencia Artificial (IA) por ser un hito significativo en el avance de la computación y la inteligencia artificial aplicada a juegos de estrategia. Deep Blue fue un superordenador desarrollado por IBM que ganó una partida de ajedrez contra el campeón mundial Garry Kasparov en 1997. Esta victoria marcó la primera vez que una máquina venció a un campeón mundial en un juego de ajedrez bajo condiciones de torneo estándar.  La relevanc","",0,true,0.703,1,0.85,0,0.5,1,0.473,2025-12-03T02:22:44.640Z
Q043,ml_clasico,basico,"¿Qué es el sobreajuste en un modelo de aprendizaje automático?","El sobreajuste ocurre cuando un modelo aprende patrones específicos del conjunto de entrenamiento y falla al generalizar a nuevos datos. Esto suele deberse a modelos demasiado complejos o falta de regularización.","El sobreajuste, también conocido como overfitting en inglés, es un fenómeno común en el aprendizaje automático donde un modelo se ajusta demasiado bien a los datos de entrenamiento. Esto significa que el modelo captura no solo el patrón subyacente en los datos, sino también el ruido aleatorio o las fluctuaciones irrelevantes que pueden estar presentes en el conjunto de entrenamiento. Como resultado, el modelo puede tener un rendimiento deficiente al generalizar con nuevos datos que no ha visto a","Introducción al Aprendizaje Automático, Universidad de Caldas",1,false,0.86,1,0.9,1,0,1,0.786,2025-12-03T02:22:44.640Z
Q044,deep_learning_llms,intermedio,"¿Qué son las capas convolucionales y para qué se utilizan?","Son capas que aplican filtros para extraer características locales de los datos, especialmente en imágenes. Permiten detectar patrones como bordes, texturas y formas mediante operaciones de convolución.","Las capas convolucionales son un componente fundamental en las redes neuronales convolucionales (CNN). Estas capas se utilizan para extraer características relevantes de los datos de entrada mediante la aplicación de filtros convolucionales. Cada filtro convolucional se desplaza a lo largo de la entrada y realiza operaciones de convolución para detectar patrones como bordes, texturas o formas en diferentes regiones de la imagen. Al combinar múltiples capas convolucionales en una CNN, se logra un","",0,true,0.933,1,0.85,0,0.5,1,0.554,2025-12-03T02:22:44.641Z
Q045,etica_regulacion,intermedio,"¿Por qué la privacidad es un principio central en el diseño de sistemas de IA?","Los sistemas de IA suelen procesar grandes volúmenes de datos personales, lo que implica riesgos de uso indebido o exposición. Proteger la privacidad garantiza la confianza pública y el cumplimiento de normas legales.","La privacidad es un principio central en el diseño de sistemas de Inteligencia Artificial (IA) debido a la importancia de proteger los datos personales y la información sensible de los individuos. En el contexto de la IA, los sistemas suelen procesar grandes cantidades de datos para aprender patrones y tomar decisiones automatizadas. Si no se garantiza la privacidad de estos datos, se corre el riesgo de violar la intimidad de las personas, exponer información confidencial y generar posibles disc","Privacy in Artificial Intelligence and Machine Learning",1,false,0.832,1,1,1,0,1,0.791,2025-12-03T02:22:44.641Z
Q046,aplicaciones,intermedio,"¿Cómo apoya la IA la detección temprana de fraudes financieros?","Modelos de IA analizan patrones de transacciones para identificar comportamientos anómalos en tiempo real. Esto permite detectar fraudes con mayor precisión y reducir pérdidas operativas.","La detección temprana de fraudes financieros se ve favorecida por la Inteligencia Artificial a través de sistemas avanzados de detección que utilizan técnicas como la fusión y correlación de alertas basadas en ontologías. Estos sistemas evalúan el tráfico en busca de comportamientos anómalos que puedan indicar posibles fraudes. La IA permite identificar patrones y secuencias de eventos que podrían pasar desapercibidos para los sistemas tradicionales de detección de fraudes.  Por ejemplo, se pued","doc_013_Fusion_Alertas_Ontologias.pdf",1,false,0.5,1,1,1,0,1,0.675,2025-12-03T02:22:44.641Z
Q047,conceptos_basicos,avanzado,"¿Qué implica la representación del conocimiento en IA?","Se refiere a las técnicas utilizadas para modelar información del mundo de manera que un sistema pueda razonar sobre ella. Incluye ontologías, lógicas formales y marcos semánticos que permiten inferencia estructurada.","La representación del conocimiento en Inteligencia Artificial (IA) es fundamental para que los sistemas puedan adquirir, almacenar y utilizar información de manera efectiva. Implica la creación de estructuras y formatos que permitan a las máquinas interpretar y manipular el conocimiento de manera similar a como lo haría un ser humano.   En IA, la representación del conocimiento puede implicar diferentes enfoques, como el uso de lenguajes formales, ontologías, redes semánticas, grafos, entre otro",""Knowledge Representation in Artificial Intelligence" - document.pdf",1,false,0.63,1,0.9,1,0,1,0.706,2025-12-03T02:22:44.641Z
Q048,historia,basico,"¿Qué logró ELIZA en los primeros años de la IA?","ELIZA fue uno de los primeros programas de procesamiento del lenguaje natural capaces de simular conversaciones simples. Su impacto mostró cómo reglas básicas podían generar interacción aparentemente humana.","En los primeros años de la Inteligencia Artificial, ELIZA fue un programa informático desarrollado por Joseph Weizenbaum en el Instituto Tecnológico de Massachusetts (MIT) en la década de 1960. ELIZA fue uno de los primeros programas de procesamiento del lenguaje natural y se destacó por simular una conversación terapéutica con los usuarios. Aunque ELIZA no tenía inteligencia ni comprensión real del lenguaje, logró sorprender a muchos usuarios al emular respuestas humanas de manera convincente. ","Documento sobre historia de la Inteligencia Artificial",1,false,0.532,1,1,1,0,1,0.686,2025-12-03T02:22:44.641Z
Q049,ml_clasico,avanzado,"¿Por qué los métodos ensemble suelen mejorar el rendimiento de un modelo?","Combinan múltiples modelos base para reducir la varianza, el sesgo o ambos, produciendo predicciones más robustas. Técnicas como bagging y boosting permiten capturar distintos patrones del conjunto de datos.","Los métodos ensemble suelen mejorar el rendimiento de un modelo debido a que combinan múltiples modelos base para obtener predicciones más precisas y robustas. Al combinar la predicción de varios modelos, se aprovecha la diversidad de enfoques y la capacidad de cada modelo para capturar diferentes aspectos de los datos. Esto ayuda a reducir el sesgo y la varianza del modelo, lo que puede conducir a una mejora en la generalización y la capacidad predictiva.  Por ejemplo, en el caso del **Random F","",0,true,0.724,1,0.85,0,0.5,1,0.481,2025-12-03T02:22:44.641Z
Q050,deep_learning_llms,basico,"¿Qué es el descenso de gradiente en el entrenamiento de redes neuronales?","Es un método iterativo que ajusta los parámetros de un modelo minimizando una función de pérdida. Calcula gradientes para determinar la dirección en la que deben modificarse los pesos para mejorar el rendimiento.","El descenso de gradiente es un algoritmo fundamental en el entrenamiento de redes neuronales en el campo del machine learning. Consiste en un método de optimización utilizado para minimizar la función de pérdida de la red neuronal ajustando los pesos de las conexiones entre las neuronas. El objetivo es encontrar los valores óptimos de los pesos que permitan a la red neuronal hacer predicciones precisas.  Durante el proceso de entrenamiento de una red neuronal, el descenso de gradiente calcula la","",0,true,0.835,1,0.9,0.3,0.5,1,0.587,2025-12-03T02:22:44.641Z
Q051,conceptos_basicos,basico,"¿Qué es el preprocesamiento de datos en un proyecto de IA?","Es el conjunto de técnicas utilizadas para limpiar, transformar y preparar los datos antes de entrenar un modelo. Incluye normalización, eliminación de valores faltantes y codificación de variables.","El preprocesamiento de datos en un proyecto de Inteligencia Artificial (IA) es una etapa crucial que implica la preparación y limpieza de los datos antes de utilizarlos para entrenar un modelo de machine learning. Consiste en una serie de técnicas y operaciones que se aplican a los datos brutos con el objetivo de hacerlos aptos para el análisis y la modelización.   Durante el preprocesamiento de datos, se realizan varias tareas como la eliminación de valores atípicos, la normalización de datos, ","",0,true,0.779,1,0.75,0,0.5,1,0.485,2025-12-03T02:22:44.641Z
Q052,historia,intermedio,"¿Qué aportó el Perceptrón al desarrollo del aprendizaje automático?","Introdujo uno de los primeros modelos de redes neuronales capaces de aprender mediante ajuste de pesos. Aunque limitado, sentó las bases para el desarrollo de métodos más avanzados.","El Perceptrón, propuesto por Frank Rosenblatt en 1957, fue un hito importante en el desarrollo del aprendizaje automático. Este modelo de red neuronal de una sola capa fue uno de los primeros en demostrar la capacidad de aprender de manera automática a partir de ejemplos. El Perceptrón es un clasificador lineal que puede aprender a separar dos clases de datos utilizando una función de activación basada en una combinación lineal de las entradas.  El aporte principal del Perceptrón fue sentar las ","",0,true,0.638,1,0.85,0,0.5,1,0.451,2025-12-03T02:22:44.641Z
Q053,ml_clasico,intermedio,"¿Qué es la validación cruzada y por qué se utiliza?","Es una técnica que divide los datos en varios subconjuntos para evaluar el desempeño del modelo de manera más robusta. Permite estimar mejor su capacidad de generalización.","La validación cruzada es una técnica utilizada en machine learning para evaluar el rendimiento de un modelo predictivo. Consiste en dividir el conjunto de datos en subconjuntos de entrenamiento y prueba de manera repetida, ajustando el modelo en los datos de entrenamiento y evaluándolo en los datos de prueba. Esto se hace varias veces con diferentes particiones de los datos, y al final se promedian los resultados para obtener una estimación más precisa del rendimiento del modelo.  La validación ","Documento de investigación sobre validación cruzada en machine learning",1,false,0.717,1,1,1,0,1,0.751,2025-12-03T02:22:44.642Z
Q054,deep_learning_llms,avanzado,"¿Qué función cumple la atención en los modelos tipo Transformer?","La atención permite que el modelo asigne importancia variable a diferentes partes de la secuencia de entrada. Esto mejora la captura de dependencias largas y la eficiencia del entrenamiento.","La atención en los modelos tipo Transformer, como los Vision Transformers (ViT), cumple una función crucial al permitir que la red se enfoque en diferentes partes de los datos de entrada y ajuste dinámicamente la importancia de cada característica. En lugar de depender de mapas de características diseñados manualmente, los Transformers utilizan mecanismos de auto-atención para aprender características directamente de los datos de entrada. Esta capacidad de atención permite a la red adaptarse a d","doc_007_PeerJ_AI_Applications.pdf",1,false,0.55,1,1,1,0,1,0.692,2025-12-03T02:22:44.642Z
Q055,etica_regulacion,avanzado,"¿Qué riesgos presenta la toma de decisiones automatizada sin supervisión humana?","Puede generar decisiones opacas, sesgadas o difíciles de impugnar. La ausencia de supervisión reduce la capacidad de corregir errores y afecta la responsabilidad y transparencia.","La toma de decisiones automatizada sin supervisión humana presenta varios riesgos significativos. Uno de los principales riesgos es el sesgo algorítmico, que puede surgir debido a datos sesgados utilizados para entrenar los modelos de inteligencia artificial. Este sesgo puede llevar a decisiones discriminatorias o injustas, especialmente en áreas como contratación, crédito, justicia penal, entre otros. Por ejemplo, si un algoritmo de contratación se entrena con datos históricos sesgados, puede p","Documento sobre Ética en Inteligencia Artificial, Universidad de Caldas",1,false,0.55,1,1,1,0,0,0.742,2025-12-03T02:22:44.642Z
Q056,aplicaciones,basico,"¿Cómo se emplea la IA en los sistemas de recomendación?","Utiliza algoritmos que analizan el comportamiento del usuario y patrones de consumo para sugerir contenido relevante. Incluye filtrado colaborativo y modelos basados en contenido.","Los sistemas de recomendación son una aplicación común de la Inteligencia Artificial (IA) que utiliza algoritmos para predecir y ofrecer recomendaciones personalizadas a los usuarios. La IA se emplea en los sistemas de recomendación para analizar grandes cantidades de datos sobre preferencias, comportamientos y patrones de los usuarios con el fin de generar recomendaciones relevantes y adaptadas a cada individuo.  En primer lugar, los sistemas de recomendación utilizan técnicas de aprendizaje au","Documento de investigación sobre sistemas de recomendación y IA, Artículo académico sobre el uso de IA en sistemas de recomendación",2,false,0.875,1,1,1,0,1,0.806,2025-12-03T02:22:44.642Z
Q057,conceptos_basicos,intermedio,"¿Qué es un modelo generativo?","Es un tipo de modelo que aprende la distribución de los datos para generar nuevas muestras similares a las originales. Incluye GANs, modelos autoregresivos y difusores.","Un modelo generativo es un tipo de modelo en el campo del aprendizaje automático que tiene la capacidad de generar nuevos datos que son similares a los datos de entrenamiento. Estos modelos aprenden la distribución de probabilidad de los datos de entrada y luego son capaces de generar muestras nuevas que se asemejan a los datos originales. En esencia, un modelo generativo puede crear datos nuevos y realistas a partir de los datos de entrada que ha aprendido.  Existen varios enfoques para la crea","Documento sobre modelos generativos en IA",1,false,0.638,1,0.9,1,0,1,0.708,2025-12-03T02:22:44.642Z
Q058,historia,avanzado,"¿Qué impacto tuvo el 'AI Winter' en la investigación de inteligencia artificial?","Provocó una caída significativa en financiamiento y expectativas debido a resultados decepcionantes. Aun así, motivó líneas más realistas y sentó bases para avances posteriores.","El ""AI Winter"" se refiere a períodos de desilusión y falta de financiamiento en el campo de la inteligencia artificial, que han ocurrido en la historia de esta disciplina. Estos períodos han tenido un impacto significativo en la investigación de inteligencia artificial, ya que han llevado a una disminución en la inversión, el interés y el progreso en el desarrollo de tecnologías de IA.  Durante los períodos de AI Winter, la falta de avances significativos y el incumplimiento de las expectativa","Understanding AI Winters and Summers - Towards Data Science",1,false,0.733,1,1,1,0,1,0.757,2025-12-03T02:22:44.643Z
Q059,ml_clasico,basico,"¿Qué diferencia hay entre clasificación y regresión?","La clasificación predice categorías discretas, mientras que la regresión estima valores numéricos continuos. Representan dos tipos fundamentales de tareas supervisadas.","La clasificación y la regresión son dos tipos de problemas en el campo del aprendizaje automático, pero difieren en su objetivo y en la naturaleza de la variable de salida que se está prediciendo.  En la clasificación, el objetivo es predecir a qué categoría o clase pertenece un dato de entrada. Es decir, se busca asignar una etiqueta o clase a cada instancia de entrada. Por ejemplo, en un problema de clasificación de correos electrónicos, se podría predecir si un correo es spam o no spam. Las s","Introducción al Aprendizaje Automático, Universidad de Caldas",1,false,0.487,1,1,1,0,1,0.67,2025-12-03T02:22:44.643Z
Q060,deep_learning_llms,intermedio,"¿Qué es el fine-tuning en modelos de lenguaje?","Es el proceso de ajustar un modelo preentrenado sobre un conjunto de datos específico para adaptarlo a una tarea concreta. Permite obtener buen desempeño con menos datos y tiempo de entrenamiento.","El fine-tuning en modelos de lenguaje se refiere a un proceso en el que un modelo pre-entrenado se ajusta o se ""sintoniza"" para una tarea específica o dominio de interés. En lugar de entrenar un modelo desde cero, el fine-tuning aprovecha un modelo pre-entrenado en una tarea más general y lo adapta para que sea más efectivo en una tarea más específica.  Durante el fine-tuning, se ajustan los pesos del modelo pre-entrenado utilizando datos específicos de la tarea objetivo. Esto permite que el m","",0,true,0.478,1,0.75,0,0.5,1,0.38,2025-12-03T02:22:44.643Z


--- RESUMEN GLOBAL ---
Total Preguntas,60
Modelo,gpt-3.5-turbo
Score Global,0.597
Tasa Alucinacion %,22.8
Porcentaje Con Citas,53.33
IFA,0.619
Aprobado,false
