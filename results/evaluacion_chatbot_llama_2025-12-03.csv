ID,Categoria,Nivel,Pregunta,Respuesta_Esperada,Respuesta_Obtenida,Fuentes,Num_Fuentes,No_Tiene_Info,Exactitud,Cobertura,Claridad,Citas,Alucinacion,Seguridad,Score_R,Timestamp
Q001,conceptos_basicos,basico,"¿Qué es la Inteligencia Artificial?","Campo de la informática que desarrolla sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como aprendizaje, razonamiento y resolución de problemas.","La Inteligencia Artificial (IA) se refiere a la capacidad de las máquinas para imitar la inteligencia humana y realizar tareas que normalmente requieren de la intervención humana. Según un documento titulado ""Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales"", se destaca que en el desarrollo de algoritmos para generar el comportamiento de agentes inteligentes, se busca que dicho comportamiento sea interpretable par","doc_004_AI_Cognitive_Models.pdf",1,false,0.44,0.533,1,1,0,1,0.561,2025-11-23T23:01:09.637Z
Q002,conceptos_basicos,intermedio,"¿Cuál es la diferencia entre IA débil e IA fuerte?","IA débil (narrow AI) está diseñada para tareas específicas, mientras que IA fuerte (general AI) tendría capacidades cognitivas generales comparables a las humanas.","La diferencia entre IA débil e IA fuerte radica en su capacidad y alcance de funcionamiento:  - **IA Débil**: También conocida como inteligencia artificial estrecha, se refiere a sistemas de IA diseñados para realizar tareas específicas y limitadas. Estos sistemas no poseen la capacidad de llevar a cabo actividades fuera de su ámbito predefinido y no tienen conciencia ni comprensión del mundo. Son especializados y dependen en gran medida de instrucciones detalladas para operar eficazmente.  - **","Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales, Vélez-Bedoya, J.I., Castillo-Ossa, L.F., González-Bedia, M.",1,false,0.557,1,1,1,0,1,0.695,2025-11-23T23:01:09.637Z
Q003,historia,basico,"¿Quién acuñó el término Inteligencia Artificial y en qué año?","John McCarthy acuñó el término en 1956 durante la Conferencia de Dartmouth.","El término ""Inteligencia Artificial"" fue acuñado por John McCarthy en el año 1956. McCarthy fue un destacado científico de la computación y pionero en el campo de la Inteligencia Artificial. Su trabajo y contribuciones fueron fundamentales para el desarrollo y la popularización de este campo de estudio.  **Referencias:** - [Fuente: doc_005_Teoria_Mente_Corporizada.pdf]","doc_005_Teoria_Mente_Corporizada.pdf",1,false,0.433,1,1,1,0,1,0.652,2025-11-23T23:01:09.637Z
Q004,historia,intermedio,"¿Qué fue el invierno de la IA?","Períodos (principalmente años 70s y finales 80s) de reducción drástica en financiamiento e interés en IA debido a expectativas no cumplidas y limitaciones técnicas.","El ""Invierno de la IA"" se refiere a un período en el que el interés y el progreso en el campo de la Inteligencia Artificial disminuyeron significativamente. Durante este tiempo, se experimentó una desaceleración en el avance de la IA y la reducción de la financiación para proyectos relacionados con esta disciplina.  En el contexto de la Inteligencia Artificial, se menciona que recientemente ha surgido un interés significativo en la comunidad de la robótica y la planificación en el desarrollo d","doc_004_AI_Cognitive_Models.pdf, doc_006_Digital_Skills_AI_Tools.pdf",2,false,0.067,1,1,1,0,1,0.523,2025-11-23T23:01:09.638Z
Q005,ml_clasico,intermedio,"¿Qué es un árbol de decisión en Machine Learning?","Modelo de aprendizaje supervisado que toma decisiones mediante una estructura de árbol donde cada nodo representa una prueba sobre un atributo y las hojas representan las decisiones finales.","Un árbol de decisión en Machine Learning es un modelo predictivo que se utiliza para representar y tomar decisiones basadas en una secuencia de reglas. Está compuesto por nodos que representan decisiones, ramas que representan las posibles salidas de esas decisiones y hojas que representan los resultados finales. Este tipo de modelo es especialmente útil para problemas de clasificación y regresión, ya que permite visualizar de manera intuitiva cómo se toman las decisiones en función de las carac","doc_004_AI_Cognitive_Models.pdf",1,false,0.65,1,1,1,0,1,0.728,2025-11-23T23:01:09.638Z
Q006,ml_clasico,avanzado,"¿Cómo funciona el algoritmo de Support Vector Machine (SVM)?","SVM encuentra el hiperplano óptimo que maximiza el margen entre clases en un espacio de características, pudiendo usar kernels para clasificación no lineal.","El algoritmo de Support Vector Machine (SVM) es un método de aprendizaje supervisado utilizado para clasificación y regresión. En el contexto de un estudio realizado, se menciona que se compararon varios algoritmos de aprendizaje automático, incluyendo el clasificador de vectores de soporte lineal (SVC), regresión logística (LR), análisis discriminante lineal (LDA), vecinos más cercanos (KNN), clasificador bayesiano ingenuo (NB), perceptrón multicapa (MLP), árboles de decisión (DT) y bosques ale","Processes_AI_Industrial.pdf",1,false,0.908,1,1,1,0,1,0.818,2025-11-23T23:01:09.638Z
Q007,deep_learning_llms,intermedio,"¿Qué es un transformer en el contexto de deep learning?","Arquitectura de red neuronal basada en mecanismos de atención que procesa secuencias en paralelo, base de modelos como GPT y BERT.","En el contexto de deep learning, un ""transformer"" se refiere a una innovadora aproximación en visión por computadora conocida como Vision Transformer (ViT). Los Vision Transformers son un enfoque revolucionario que ha ganado popularidad recientemente debido a su impresionante rendimiento en diversas tareas. A diferencia de las redes neuronales convolucionales tradicionales (CNN), que dependen de mapas de características diseñados manualmente, los vision transformers utilizan mecanismos de auto","doc_007_PeerJ_AI_Applications.pdf",1,false,0.462,1,1,1,0,1,0.662,2025-11-23T23:01:09.638Z
Q008,deep_learning_llms,avanzado,"¿Qué es el fine-tuning en Large Language Models?","Proceso de ajustar un modelo preentrenado con datos específicos de una tarea o dominio para mejorar su desempeño en aplicaciones particulares.","El fine-tuning en Large Language Models se refiere al proceso de ajustar un modelo de lenguaje preentrenado para adaptarlo a una tarea específica o dominio de interés. Este proceso implica tomar un modelo de lenguaje general, como BERT o GPT, y continuar el entrenamiento con datos específicos y etiquetados para mejorar su desempeño en una tarea particular.  Durante el fine-tuning, se ajustan los pesos del modelo preentrenado mediante el uso de datos adicionales y técnicas de optimización para qu","Processes_AI_Industrial.pdf",1,false,0.517,1,1,1,0,1,0.681,2025-11-23T23:01:09.638Z
Q009,etica_regulacion,intermedio,"¿Qué es el AI Act de la Unión Europea?","Marco regulatorio que clasifica sistemas de IA según riesgo y establece requisitos de transparencia, seguridad y derechos fundamentales.","El AI Act de la Unión Europea es una legislación propuesta que busca regular el uso de la inteligencia artificial en la Unión Europea. Esta normativa tiene como objetivo establecer un marco ético y legal para garantizar un uso seguro y ético de la inteligencia artificial en diversos sectores.  El AI Act aborda aspectos clave como la transparencia, la responsabilidad, la supervisión y el control de los sistemas de inteligencia artificial. Busca proteger los derechos fundamentales de los ciudadano","doc_014_Springer_AI_ML_Review.pdf, doc_016_Constitucion_Colombia_2024.pdf",2,false,0.567,1,1,1,0,1,0.698,2025-11-23T23:01:09.639Z
Q010,aplicaciones,basico,"¿Cuáles son tres aplicaciones comunes de IA en la vida cotidiana?","Asistentes virtuales (Siri, Alexa), sistemas de recomendación (Netflix, Spotify) y reconocimiento facial en smartphones.","En la vida cotidiana, la Inteligencia Artificial (IA) se ha integrado en diversas aplicaciones que impactan directamente en nuestra calidad de vida. Tres aplicaciones comunes de la IA son:  1. **Sector de la Salud**: La IA está siendo utilizada en el sector de la salud para mejorar la atención médica, diagnósticos más precisos y personalizados, identificación de patrones en grandes conjuntos de datos médicos, y en la investigación de enfermedades. Estos sistemas basados en IA pueden contribuir s","",0,true,0.186,0.475,1,0.3,0.5,1,0.27,2025-11-23T23:01:09.639Z
Q011,conceptos_basicos,basico,"¿Qué se entiende por inteligencia artificial en el contexto computacional?","Es el campo de estudio que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana. Incluye técnicas para percibir, razonar, aprender y tomar decisiones basadas en datos.","En el contexto computacional, la inteligencia artificial se refiere a la capacidad de los agentes inteligentes para generar comportamientos interpretables por los humanos. Se destaca la importancia de la interpretabilidad en el diseño de agentes de IA con conciencia humana, donde se busca que el observador pueda comprender los objetivos, planes o recompensas atribuidas al agente a partir de sus observaciones. Este enfoque busca superar los desafíos de la interpretabilidad en el diseño de agentes","doc_004_AI_Cognitive_Models.pdf",1,false,0.226,0.533,1,1,0,1,0.486,2025-11-23T23:01:09.639Z
Q012,historia,intermedio,"¿Cuál fue el impacto de la Conferencia de Dartmouth en el desarrollo de la IA?","La Conferencia de Dartmouth de 1956 marcó el inicio formal de la IA como disciplina académica. Reunió a investigadores clave y estableció una agenda para explorar máquinas capaces de simular la inteligencia humana.","La Conferencia de Dartmouth, celebrada en 1956, tuvo un impacto significativo en el desarrollo de la Inteligencia Artificial (IA). En esta conferencia pionera, se sentaron las bases y se establecieron los objetivos iniciales para la investigación en IA. Uno de los resultados más importantes de la Conferencia de Dartmouth fue la definición del campo de estudio de la IA y la formulación de las primeras ideas sobre cómo simular el pensamiento humano a través de máquinas.  Los participantes de la co","",0,true,0.606,1,1,0.3,0.5,1,0.522,2025-11-23T23:01:09.639Z
Q013,ml_clasico,intermedio,"¿En qué consiste la regresión logística y para qué tipo de problemas se utiliza?","La regresión logística es un modelo estadístico que estima la probabilidad de pertenencia a una clase binaria usando una función sigmoide. Se emplea ampliamente en tareas de clasificación como detección de spam o diagnóstico médico.","La regresión logística es un algoritmo de aprendizaje supervisado utilizado en problemas de clasificación. Aunque su nombre incluye la palabra ""regresión"", en realidad se emplea para predecir la probabilidad de que una observación pertenezca a una determinada categoría.   En la regresión logística, se ajusta una curva logística a los datos para modelar la relación entre las variables independientes y la variable dependiente categórica. Esta curva logística se utiliza para estimar la probabilid","doc_004_AI_Cognitive_Models.pdf, doc_013_Fusion_Alertas_Ontologias.pdf",2,false,0.661,1,0.9,1,0,1,0.716,2025-11-23T23:01:09.640Z
Q014,deep_learning_llms,intermedio,"¿Qué ventaja principal introdujo la arquitectura Transformer en comparación con las redes recurrentes?","Los Transformers permiten procesar secuencias completas en paralelo mediante mecanismos de atención, eliminando la dependencia estricta del orden secuencial. Esto mejora la eficiencia computacional y capta mejor relaciones de largo alcance.","La arquitectura Transformer introdujo una ventaja principal significativa en comparación con las redes recurrentes, especialmente en el procesamiento de secuencias largas. La principal ventaja radica en su capacidad para capturar dependencias a largo plazo de manera más efectiva que las redes recurrentes.  En las redes recurrentes, como las LSTM (Long Short-Term Memory) y las GRU (Gated Recurrent Unit), la información se propaga a través de conexiones recurrentes a lo largo de la secuencia. Sin ","doc_004_AI_Cognitive_Models.pdf",1,false,0.65,1,1,1,0,1,0.728,2025-11-23T23:01:09.640Z
Q015,etica_regulacion,avanzado,"¿Por qué el sesgo algorítmico es un riesgo crítico en sistemas de IA utilizados para decisiones públicas?","El sesgo algorítmico puede amplificar desigualdades existentes cuando se usan datos históricos no representativos o discriminatorios. En decisiones públicas, esto afecta la equidad y puede vulnerar derechos fundamentales.","El sesgo algorítmico es un riesgo crítico en sistemas de IA utilizados para decisiones públicas debido a varios factores. En primer lugar, el sesgo puede surgir en los datos utilizados para entrenar los algoritmos, lo que puede llevar a decisiones discriminatorias o injustas. Los algoritmos de IA aprenden de conjuntos de datos históricos que pueden reflejar sesgos existentes en la sociedad, como discriminación racial o de género, y perpetuarlos en las decisiones automatizadas.  Además, la opacid","doc_004_AI_Cognitive_Models.pdf",1,false,0.511,1,1,1,0,0,0.729,2025-11-23T23:01:09.641Z
Q016,aplicaciones,basico,"¿Cómo se utiliza la IA en los sistemas de recomendación?","Estos sistemas analizan patrones de comportamiento y preferencias del usuario para sugerir contenidos relevantes. Emplean técnicas de filtrado colaborativo y modelos predictivos para mejorar la personalización.","Los sistemas de recomendación utilizan Inteligencia Artificial (IA) para analizar datos y proporcionar recomendaciones personalizadas a los usuarios. En un artículo titulado ""Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales"", se menciona que la IA se utiliza en el desarrollo de algoritmos que generen comportamientos interpretables para los agentes inteligentes. La interpretabilidad en este contexto se refiere a la","doc_004_AI_Cognitive_Models.pdf",1,false,0.306,1,1,1,0,1,0.607,2025-11-23T23:01:09.641Z
Q017,conceptos_basicos,intermedio,"¿Qué diferencia al aprendizaje supervisado del no supervisado?","El aprendizaje supervisado utiliza datos etiquetados para entrenar modelos que predicen valores o clases específicas. El no supervisado busca patrones o estructuras ocultas en datos sin etiquetar, como agrupamientos.","El aprendizaje supervisado y el no supervisado son dos enfoques fundamentales en el campo del machine learning que se diferencian en la forma en que se realiza el entrenamiento de los modelos:  1. **Aprendizaje Supervisado**:    - En el aprendizaje supervisado, el modelo recibe ejemplos etiquetados como entrada durante el proceso de entrenamiento. Estos ejemplos consisten en pares de entrada y salida esperada, lo que permite al modelo aprender a mapear las entradas a las salidas.    - El objetiv","doc_004_AI_Cognitive_Models.pdf, doc_013_Fusion_Alertas_Ontologias.pdf",2,false,0.832,0.65,0.9,1,0,1,0.706,2025-11-23T23:01:09.641Z
Q018,ml_clasico,avanzado,"¿Qué papel juega el margen en los modelos SVM y por qué es relevante?","El margen es la distancia entre el hiperplano de separación y los puntos más cercanos de cada clase. Maximizarlo mejora la capacidad de generalización y reduce la sensibilidad al ruido del modelo.","El margen en los modelos de Máquinas de Vectores de Soporte (SVM) juega un papel crucial en la clasificación de datos. El margen se refiere a la distancia entre el hiperplano de separación y los puntos de datos más cercanos de cada clase. Es relevante en SVM porque ayuda a determinar la capacidad del modelo para generalizar y clasificar correctamente nuevos datos.  En SVM, el objetivo es encontrar el hiperplano de separación que maximice el margen entre las clases. Un margen más amplio indica un","doc_015_Processes_AI_Industrial.pdf",1,false,0.9,1,0.9,1,0,1,0.8,2025-11-23T23:01:09.641Z
Q019,deep_learning_llms,avanzado,"¿Por qué los modelos de lenguaje a gran escala pueden presentar alucinaciones en sus respuestas?","Estas alucinaciones surgen cuando el modelo genera información plausible pero incorrecta debido a patrones estadísticos aprendidos sin comprensión semántica real. También se relacionan con datos incompletos, sesgos y la naturaleza probabilística de la generación.","Los modelos de lenguaje a gran escala pueden presentar alucinaciones en sus respuestas debido a comportamientos poco predictivos derivados de modelos cognitivos artificiales. En un estudio realizado se menciona que al desarrollar modelos comportamentales con arquitecturas disímiles, como la arquitectura cognitiva SOAR, se pueden observar alucinaciones en las respuestas. Estas alucinaciones pueden surgir en situaciones donde los modelos no logran predecir de manera precisa las acciones de un agen","doc_004_AI_Cognitive_Models.pdf",1,false,0.439,0.65,1,1,0,1,0.584,2025-11-23T23:01:09.641Z
Q020,aplicaciones,intermedio,"¿Cómo puede la IA apoyar el diagnóstico médico asistido?","Los modelos de IA analizan imágenes, registros clínicos y patrones de síntomas para ayudar a identificar posibles enfermedades. Funcionan como herramientas de apoyo que aumentan la precisión y rapidez del diagnóstico, pero no sustituyen el criterio clínico.","La Inteligencia Artificial (IA) puede apoyar el diagnóstico médico de diversas formas, incluyendo el análisis de datos de pacientes para identificar similitudes y diferencias, la personalización del monitoreo de pacientes con trastornos mentales mediante la minería de datos, y la predicción de datos médicos y eventos para pacientes con enfermedades crónicas en entornos hospitalarios y domiciliarios. Estas aplicaciones de IA utilizan herramientas de minería de datos para mejorar la precisión en e","",0,true,0.395,0.533,1,0.3,0.5,1,0.355,2025-11-23T23:01:09.641Z
Q021,conceptos_basicos,basico,"¿Qué es un agente inteligente en IA?","Es una entidad que percibe su entorno mediante sensores y actúa sobre él mediante actuadores. Su objetivo es seleccionar acciones que maximicen su desempeño según una medida definida.","Un agente inteligente en Inteligencia Artificial (IA) es un sistema diseñado para percibir su entorno, tomar acciones autónomas para lograr objetivos y mejorar su rendimiento a través del aprendizaje y la adquisición de conocimiento. Estos agentes son utilizados en diversas tareas de toma de decisiones en campos como videojuegos, conducción autónoma y sistemas de IoT, entre otros.  Según la literatura consultada, se destaca que la interpretabilidad es un desafío importante en el diseño de agente","",0,true,0.544,1,1,0.3,0.5,1,0.5,2025-11-23T23:01:09.641Z
Q022,historia,intermedio,"¿Qué aportó Alan Turing al desarrollo de la inteligencia artificial?","Turing propuso el modelo computacional que fundamenta el concepto de algoritmo y la idea de una máquina universal. También formuló la Prueba de Turing como criterio para evaluar el comportamiento inteligente en máquinas.","Alan Turing realizó una contribución fundamental al desarrollo de la inteligencia artificial a través de su concepto de la ""Máquina de Turing"". Este concepto es la base teórica de la computación moderna y sentó los cimientos para la creación de algoritmos y programas que imitan la inteligencia humana.  La Máquina de Turing es un modelo abstracto de un dispositivo que manipula símbolos en una cinta de acuerdo con reglas específicas. Este concepto permitió demostrar que cualquier problema matemá","",0,true,0.739,1,0.9,0.3,0.5,1,0.554,2025-11-23T23:01:09.642Z
Q023,ml_clasico,basico,"¿Qué es un árbol de decisión y para qué se utiliza?","Es un modelo que divide iterativamente el espacio de datos mediante reglas simples para realizar clasificación o regresión. Su estructura jerárquica facilita la interpretación y el análisis de decisiones.","Un árbol de decisión es una técnica de modelado predictivo utilizada en el campo de la Inteligencia Artificial. Se utiliza para representar y visualizar decisiones y sus posibles consecuencias en forma de un árbol. Cada nodo interno del árbol representa una característica (atributo), cada rama representa una decisión basada en esa característica, y cada hoja representa el resultado de la decisión.   Los árboles de decisión son ampliamente utilizados en diversas áreas, como la clasificación y la ","doc_004_AI_Cognitive_Models.pdf, doc_016_Constitucion_Colombia_2024.pdf",2,false,0.662,1,0.9,1,0,1,0.717,2025-11-23T23:01:09.642Z
Q024,deep_learning_llms,intermedio,"¿Qué papel cumplen las funciones de activación en una red neuronal profunda?","Permiten introducir no linealidad en las capas, lo que habilita a la red para aprender representaciones complejas. Activaciones como ReLU o tanh ayudan a controlar gradientes y mejorar la estabilidad del entrenamiento.","Las funciones de activación desempeñan un papel fundamental en una red neuronal profunda al introducir no linealidades en el modelo, permitiendo a la red aprender y modelar relaciones complejas en los datos. En el proceso de entrenamiento de una red neuronal profunda, las funciones de activación son aplicadas a la salida de cada neurona, determinando si y en qué medida la neurona debe activarse. Esto es crucial para la capacidad de la red para aprender y generalizar patrones en los datos de entr","doc_004_AI_Cognitive_Models.pdf",1,false,0.733,1,1,1,0,1,0.757,2025-11-23T23:01:09.642Z
Q025,etica_regulacion,intermedio,"¿Por qué es importante la transparencia en los sistemas de IA?","La transparencia facilita comprender cómo un sistema llega a sus decisiones, lo que mejora la confianza y la rendición de cuentas. Además, permite detectar errores, sesgos y riesgos de impacto social.","La transparencia en los sistemas de Inteligencia Artificial (IA) es fundamental por varias razones. En primer lugar, la falta de transparencia en los sistemas basados en IA puede ser un obstáculo significativo para su uso. Por esta razón, se ha aplicado la Inteligencia Artificial Explicable (XAI) para hacer que estos sistemas sean comprensibles y transparentes para los usuarios. La transparencia es clave para garantizar la confianza en los sistemas de IA y para permitir que los usuarios comprend","",0,true,0.544,1,0.9,0.3,0.5,0,0.536,2025-11-23T23:01:09.642Z
Q026,aplicaciones,avanzado,"¿Cómo puede la IA optimizar procesos en cadenas de suministro?","Modelos predictivos anticipan demanda, ajustan inventarios y mejoran decisiones logísticas en tiempo real. Esto reduce costos, incrementa eficiencia y permite adaptarse rápidamente a condiciones cambiantes.","La Inteligencia Artificial (IA) puede optimizar procesos en cadenas de suministro de diversas formas. Una de las aplicaciones clave es la gestión de inventarios, donde la IA puede predecir la demanda futura y optimizar los niveles de inventario para minimizar costos y evitar escasez o exceso de productos. Además, la IA puede mejorar la planificación logística al optimizar rutas de transporte, tiempos de entrega y asignación de recursos.  En el contexto de la correlación de alertas en sistemas de","doc_004_AI_Cognitive_Models.pdf, doc_013_Fusion_Alertas_Ontologias.pdf",2,false,0.447,1,1,1,0,1,0.657,2025-11-23T23:01:09.642Z
Q027,conceptos_basicos,intermedio,"¿Qué es el espacio de búsqueda en un problema de IA?","Es el conjunto de todos los estados posibles que puede adoptar un sistema al intentar resolver una tarea. Definir y explorar eficazmente este espacio es esencial para algoritmos como búsqueda heurística.","El espacio de búsqueda en un problema de Inteligencia Artificial se refiere al conjunto de posibles estados y acciones que un agente puede explorar para encontrar una solución óptima. En el desarrollo de algoritmos para generar el comportamiento de agentes inteligentes, es fundamental considerar el espacio de búsqueda para garantizar que el agente pueda tomar decisiones efectivas y alcanzar sus objetivos de manera eficiente.  Según un artículo académico, en la comunidad de la robótica y la plani","Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales (doc_004_AI_Cognitive_Models.pdf)",1,false,0.5,1,1,1,0,1,0.675,2025-11-23T23:01:09.642Z
Q028,historia,avanzado,"¿Cuál fue la relevancia del perceptrón en los primeros desarrollos del aprendizaje automático?","El perceptrón introdujo un modelo formal para el aprendizaje lineal y despertó un gran entusiasmo inicial por las redes neuronales. Sin embargo, sus limitaciones teóricas llevaron a un estancamiento temporal, que más tarde se superó con técnicas de entrenamiento profundo.","El perceptrón fue de gran relevancia en los primeros desarrollos del aprendizaje automático. Se considera como uno de los primeros modelos de neurona artificial y sentó las bases para el desarrollo de redes neuronales más complejas. En la actualidad, el perceptrón simple ha evolucionado hacia redes neuronales más sofisticadas, como las redes neuronales convolucionales (CNN) utilizadas en el Deep Learning.  El trabajo futuro en este campo incluye la incorporación de redes neuronales convolucional","doc_004_AI_Cognitive_Models.pdf, doc_005_Teoria_Mente_Corporizada.pdf",2,false,0.409,0.767,1,1,0,1,0.597,2025-11-23T23:01:09.643Z
Q029,ml_clasico,intermedio,"¿Para qué se utiliza el algoritmo k-means y cómo funciona a nivel general?","k-means agrupa datos en k clústeres asignando cada punto al centro más cercano y ajustando estos centros iterativamente. Es un método eficiente para revelar estructuras internas en datos no etiquetados.","El algoritmo K-means se utiliza para detectar clusters en un conjunto de elementos de muestra, permitiendo la clasificación de estos elementos en grupos basados en similitudes y diferencias. Funciona como un método de aprendizaje no supervisado que busca minimizar la función objetivo, que en este caso es la distancia interna entre los elementos, es decir, la cercanía hacia los vectores de características comunes.  A nivel general, el algoritmo K-means opera de la siguiente manera: 1. Se iniciali","doc_013_Fusion_Alertas_Ontologias.pdf",1,false,0.297,1,1,1,0,1,0.604,2025-11-23T23:01:09.643Z
Q030,deep_learning_llms,avanzado,"¿Qué son los embeddings y por qué son esenciales en el procesamiento del lenguaje natural?","Los embeddings representan palabras o tokens como vectores densos que capturan relaciones semánticas y sintácticas. Permiten a los modelos operar en un espacio continuo donde similitudes lingüísticas pueden aprenderse y explotarse.","Los embeddings son representaciones vectoriales de palabras o frases que capturan el significado semántico y contextual de las mismas. Son esenciales en el procesamiento del lenguaje natural debido a varias razones:  1. **Representación Semántica**: Los embeddings permiten representar palabras en un espacio vectorial donde palabras similares en significado están cercanas entre sí. Esto facilita tareas como la búsqueda de sinónimos, detección de analogías y clustering de palabras relacionadas.  2","doc_004_AI_Cognitive_Models.pdf, doc_005_Teoria_Mente_Corporizada.pdf",2,false,0.529,1,1,1,0,1,0.685,2025-11-23T23:01:09.643Z
Q031,conceptos_basicos,basico,"¿Qué es un sistema experto en inteligencia artificial?","Es un programa diseñado para imitar la toma de decisiones de un especialista humano en un dominio específico. Utiliza una base de conocimientos y un motor de inferencia para resolver problemas complejos.","Un sistema experto en inteligencia artificial es un tipo de sistema informático diseñado para imitar el comportamiento y la toma de decisiones de un experto humano en un dominio específico. Estos sistemas utilizan bases de conocimiento, reglas de inferencia y mecanismos de razonamiento para resolver problemas complejos en un área particular. Según Chakraborti et al. (2019), en el desarrollo de algoritmos para generar el comportamiento de agentes inteligentes, se busca que este sea interpretable ","doc_004_AI_Cognitive_Models.pdf, doc_011_Electronics_AI_Apps.pdf",2,false,0.493,1,1,1,0,1,0.673,2025-11-23T23:01:09.644Z
Q032,historia,intermedio,"¿Qué ocurrió durante el primer 'invierno de la IA'?","El primer invierno de la IA fue un periodo de recortes de financiamiento y desinterés debido a expectativas no cumplidas. Las limitaciones técnicas y el escepticismo frenaron el avance del campo durante varios años.","Durante el primer 'invierno de la IA', se observó un interés significativo en la comunidad de la robótica y la planificación en el desarrollo de algoritmos que puedan generar comportamientos de agentes interpretables para los humanos. Este interés se centró en la creación de agentes inteligentes cuyas acciones y decisiones pudieran ser comprendidas por los observadores humanos a lo largo de su ciclo de vida. La noción de interpretabilidad se refiere a la capacidad de los agentes de IA para actua","doc_004_AI_Cognitive_Models.pdf, p. 18-31",1,false,0.418,1,1,1,0,1,0.646,2025-11-23T23:01:09.644Z
Q033,ml_clasico,intermedio,"¿Qué es la validación cruzada y por qué se utiliza?","Es una técnica que divide los datos en subconjuntos para entrenar y evaluar un modelo múltiples veces. Permite estimar su desempeño general y reducir el riesgo de sobreajuste.","La validación cruzada es una técnica utilizada en machine learning para evaluar el rendimiento de un modelo predictivo. Consiste en dividir el conjunto de datos en subconjuntos de entrenamiento y prueba de manera repetida, ajustando el modelo en cada iteración y evaluando su desempeño. Esta técnica es fundamental para estimar cómo se comportará el modelo con datos no vistos, evitando problemas de sobreajuste y subajuste.  La validación cruzada se utiliza para abordar la necesidad de evaluar la c","doc_013_Fusion_Alertas_Ontologias.pdf",1,false,0.9,1,1,1,0,1,0.815,2025-11-23T23:01:09.644Z
Q034,deep_learning_llms,intermedio,"¿Cuál es la función del mecanismo de atención en una red neuronal?","El mecanismo de atención permite ponderar la relevancia de distintas partes de una entrada al generar una salida. Esto mejora la capacidad del modelo para capturar dependencias complejas y relaciones a largo plazo.","El mecanismo de atención en una red neuronal es fundamental para asignar diferentes pesos a las entradas en función de su relevancia para la tarea en cuestión. Este mecanismo permite a la red enfocarse en partes específicas de la entrada, lo que mejora la eficiencia y efectividad del proceso de aprendizaje y predicción.  Según la literatura consultada, una posibilidad para trabajar con modelos que incorporan mecanismos de atención es mediante la utilización de redes neuronales convolucionales (C","doc_004_AI_Cognitive_Models.pdf",1,false,0.339,1,1,1,0,1,0.619,2025-11-23T23:01:09.644Z
Q035,etica_regulacion,avanzado,"¿Qué desafíos presenta la responsabilidad legal en sistemas autónomos?","Los sistemas autónomos complican la atribución de responsabilidad cuando ocurren fallos o daños, ya que intervienen múltiples actores. Esto exige marcos regulatorios claros que definan obligaciones y niveles de supervisión.","La responsabilidad legal en sistemas autónomos presenta diversos desafíos que deben abordarse para garantizar su correcto funcionamiento y mitigar posibles riesgos. Algunos de los desafíos más relevantes incluyen:  1. **Asignación de Responsabilidad**: Determinar quién es responsable en caso de que un sistema autónomo cause daños o cometa errores es un desafío crucial. La falta de claridad en la asignación de responsabilidades puede generar conflictos legales y dificultar la compensación a las p","",0,true,0.33,1,1,0.3,0.8,1,0.396,2025-11-23T23:01:09.644Z
Q036,aplicaciones,basico,"¿Cómo se aplica la IA en el análisis de imágenes médicas?","La IA detecta patrones en imágenes como radiografías o resonancias para identificar posibles anomalías. Esto ayuda a apoyar diagnósticos tempranos y aumentar la precisión clínica.","El análisis de imágenes médicas con Inteligencia Artificial (IA) es una aplicación crucial en el campo de la salud. Algunas de las formas en las que se aplica la IA en este contexto incluyen:  1. **Diagnóstico de Enfermedades**: La IA se utiliza para analizar imágenes médicas, como resonancias magnéticas, radiografías y tomografías computarizadas, para ayudar en el diagnóstico de enfermedades. Por ejemplo, se han evaluado diversas técnicas de clasificación de aprendizaje automático para el diagn","",0,true,0.84,1,1,0.3,0.5,0,0.654,2025-11-23T23:01:09.644Z
Q037,conceptos_basicos,intermedio,"¿Qué diferencia existe entre un problema determinista y uno estocástico en IA?","En un problema determinista las acciones producen resultados predecibles, mientras que en uno estocástico existe incertidumbre en los efectos de las acciones. Esta diferencia condiciona los métodos de planificación y toma de decisiones.","En el contexto de la Inteligencia Artificial, la diferencia entre un problema determinista y uno estocástico radica en la naturaleza de la salida o resultado esperado ante una determinada entrada.   - **Problema Determinista**: En los problemas deterministas, la salida o resultado es predecible y único para cada entrada dada. Esto significa que, dada una entrada específica, el resultado siempre será el mismo. Las técnicas reactivas, que son deterministas, ofrecen la ventaja de conocer la salida ","doc_004_AI_Cognitive_Models.pdf",1,false,0.591,1,0.9,1,0,1,0.692,2025-11-23T23:01:09.644Z
Q038,historia,basico,"¿Quién fue John McCarthy y por qué es importante para la IA?","John McCarthy fue uno de los fundadores de la IA y acuñó el término en 1956. También desarrolló el lenguaje LISP, fundamental para los primeros sistemas de investigación en IA.","John McCarthy fue un destacado científico de la computación y pionero en el campo de la Inteligencia Artificial (IA). Es conocido por ser el creador del término ""Inteligencia Artificial"" y por sus contribuciones significativas al desarrollo de esta disciplina.  McCarthy es importante para la IA por varias razones:  1. **Creación del término ""Inteligencia Artificial"":** En 1956, McCarthy organizó la Conferencia de Dartmouth, donde se acuñó el término ""Inteligencia Artificial"" para describir","doc_005_Teoria_Mente_Corporizada.pdf, doc_008_Pervasive_Games_Rehabilitation.pdf, doc_013_Fusion_Alertas_Ontologias.pdf, doc_004_AI_Cognitive_Models.pdf",4,false,0.705,1,1,0.8,0,1,0.707,2025-11-23T23:01:09.645Z
Q039,ml_clasico,avanzado,"¿Qué es la regularización L1 y cómo afecta a los modelos?","La regularización L1 agrega una penalización basada en la magnitud absoluta de los coeficientes, promoviendo soluciones dispersas. Esto ayuda a seleccionar características relevantes y reducir el sobreajuste.","Basándome en la información recuperada, no se encontró información relevante sobre la regularización L1 y su impacto en los modelos en los documentos consultados.  Por favor, ¿hay algo más en lo que pueda ayudarte?","",0,true,0.35,1,0.85,0,0.5,1,0.35,2025-11-23T23:01:09.645Z
Q040,deep_learning_llms,avanzado,"¿Qué es el fine-tuning en modelos de lenguaje y para qué se utiliza?","El fine-tuning consiste en ajustar un modelo preentrenado usando un conjunto de datos específico para una tarea concreta. Esto permite aprovechar el conocimiento general adquirido y adaptarlo a dominios especializados.","El fine-tuning en modelos de lenguaje se refiere a un proceso en el cual un modelo pre-entrenado se ajusta o ""sintoniza"" con datos específicos de una tarea o dominio particular. Este ajuste adicional permite mejorar el rendimiento del modelo en tareas específicas sin necesidad de entrenarlo desde cero. El fine-tuning es una técnica comúnmente utilizada en el campo del aprendizaje automático y la inteligencia artificial para adaptar modelos pre-entrenados a nuevas tareas o conjuntos de datos.  ","doc_004_AI_Cognitive_Models.pdf, doc_013_Fusion_Alertas_Ontologias.pdf",2,false,0.489,1,1,1,0,1,0.671,2025-11-23T23:01:09.645Z
Q041,conceptos_basicos,basico,"¿Qué es un algoritmo heurístico en IA?","Es un método que utiliza aproximaciones o reglas prácticas para encontrar soluciones satisfactorias cuando una búsqueda exhaustiva es inviable. Las heurísticas permiten acelerar la resolución de problemas complejos sacrificando exactitud perfecta.","Un algoritmo heurístico en Inteligencia Artificial es una técnica que se utiliza para encontrar soluciones aproximadas a problemas complejos, especialmente cuando los métodos exactos son computacionalmente costosos o no factibles. Estos algoritmos se basan en reglas generales o experiencias previas para guiar la búsqueda de soluciones aceptables en un tiempo razonable.  Según la literatura consultada, los algoritmos heurísticos son relevantes en el campo de la robótica y la planificación, ya que","Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales, Vélez-Bedoya, J.I., Castillo-Ossa, L.F., González-Bedia, M.",1,false,0.64,1,1,1,0,1,0.724,2025-11-23T23:01:09.645Z
Q042,historia,intermedio,"¿Por qué el desarrollo de Deep Blue fue relevante en la historia de la IA?","Deep Blue fue el primer sistema en derrotar a un campeón mundial de ajedrez, demostrando la capacidad de las máquinas para superar a expertos humanos en tareas estructuradas. Su éxito impulsó el interés en la IA y la computación de alto rendimiento.","El desarrollo de Deep Blue fue altamente relevante en la historia de la Inteligencia Artificial por varias razones significativas:  1. Avance en el campo de la IA: Deep Blue fue un sistema de computadora desarrollado por IBM que logró vencer al campeón mundial de ajedrez, Garry Kasparov, en 1997. Este hito marcó un avance significativo en el campo de la IA al demostrar la capacidad de las máquinas para superar a los humanos en tareas complejas y estratégicas como el ajedrez.  2. Impulso a la inv","doc_004_AI_Cognitive_Models.pdf, doc_014_Springer_AI_ML_Review.pdf",2,false,0.724,1,1,1,0,1,0.753,2025-11-23T23:01:09.645Z
Q043,ml_clasico,basico,"¿Qué es el sobreajuste en un modelo de aprendizaje automático?","El sobreajuste ocurre cuando un modelo aprende patrones específicos del conjunto de entrenamiento y falla al generalizar a nuevos datos. Esto suele deberse a modelos demasiado complejos o falta de regularización.","El sobreajuste en un modelo de aprendizaje automático ocurre cuando el modelo se ajusta demasiado bien a los datos de entrenamiento, lo que puede resultar en un rendimiento deficiente en datos nuevos o no vistos anteriormente. Esto significa que el modelo ha aprendido patrones específicos de los datos de entrenamiento que no son generalizables y que no se aplican a otros conjuntos de datos.  En el contexto de la Inteligencia Artificial, se ha explorado la posibilidad de incorporar redes neuronal","doc_004_AI_Cognitive_Models.pdf",1,false,0.71,1,0.9,1,0,1,0.734,2025-11-23T23:01:09.645Z
Q044,deep_learning_llms,intermedio,"¿Qué son las capas convolucionales y para qué se utilizan?","Son capas que aplican filtros para extraer características locales de los datos, especialmente en imágenes. Permiten detectar patrones como bordes, texturas y formas mediante operaciones de convolución.","Las capas convolucionales son un componente fundamental en las redes neuronales convolucionales (CNN). Estas capas se utilizan principalmente en el procesamiento de imágenes y reconocimiento visual. En el contexto de la inteligencia artificial, se menciona que las redes neuronales convolucionales se pueden incorporar para analizar cada fotografía de manera que sea transformada por el proceso de convolución. Esto permite que la red pueda procesar y evaluar estados sobre estructuras de datos de ma","doc_004_AI_Cognitive_Models.pdf, doc_007_PeerJ_AI_Applications.pdf",2,false,0.844,1,1,1,0,1,0.796,2025-11-23T23:01:09.646Z
Q045,etica_regulacion,intermedio,"¿Por qué la privacidad es un principio central en el diseño de sistemas de IA?","Los sistemas de IA suelen procesar grandes volúmenes de datos personales, lo que implica riesgos de uso indebido o exposición. Proteger la privacidad garantiza la confianza pública y el cumplimiento de normas legales.","La privacidad es un principio central en el diseño de sistemas de IA por varias razones fundamentales:  1. **Garantía contra el robo de información y uso indebido**: La privacidad en el contexto de la IA se refiere a la protección de los datos personales y la información sensible de los individuos. Es crucial para evitar el robo de información y su mal uso con fines poco éticos. Se busca asegurar que los datos sean utilizados de manera ética y legal, protegiendo la intimidad y los derechos de la","doc_012_Redes_Sensores_Analisis.pdf, doc_014_Springer_AI_ML_Review.pdf",2,false,0.768,1,1,1,0,0,0.819,2025-11-23T23:01:09.646Z
Q046,aplicaciones,intermedio,"¿Cómo apoya la IA la detección temprana de fraudes financieros?","Modelos de IA analizan patrones de transacciones para identificar comportamientos anómalos en tiempo real. Esto permite detectar fraudes con mayor precisión y reducir pérdidas operativas.","La detección temprana de fraudes financieros se ve favorecida por el uso de la Inteligencia Artificial (IA) a través de sistemas avanzados de detección de intrusiones. Estos sistemas evalúan el tráfico en busca de comportamientos anómalos que puedan indicar posibles fraudes.   Un enfoque importante es la utilización de redes trampa/señuelo (honeynet) que contribuyen a identificar la taxonomía de los atacantes. Se ha desarrollado un modelo de detección de ataques que emplea sistemas multi-agentes","doc_013_Fusion_Alertas_Ontologias.pdf",1,false,0.45,1,0.9,1,0,1,0.643,2025-11-23T23:01:09.646Z
Q047,conceptos_basicos,avanzado,"¿Qué implica la representación del conocimiento en IA?","Se refiere a las técnicas utilizadas para modelar información del mundo de manera que un sistema pueda razonar sobre ella. Incluye ontologías, lógicas formales y marcos semánticos que permiten inferencia estructurada.","La representación del conocimiento en Inteligencia Artificial (IA) implica la formalización y estructuración de información para que pueda ser utilizada por sistemas inteligentes en diferentes tareas. En el campo de la IA, se busca desarrollar algoritmos y modelos que puedan generar comportamientos interpretables para los humanos, lo cual es un desafío importante en el diseño de agentes de IA con conciencia humana. La interpretabilidad se refiere a la capacidad de explicar el comportamiento de l","doc_004_AI_Cognitive_Models.pdf, doc_013_Fusion_Alertas_Ontologias.pdf",2,false,0.59,1,1,1,0,1,0.706,2025-11-23T23:01:09.646Z
Q048,historia,basico,"¿Qué logró ELIZA en los primeros años de la IA?","ELIZA fue uno de los primeros programas de procesamiento del lenguaje natural capaces de simular conversaciones simples. Su impacto mostró cómo reglas básicas podían generar interacción aparentemente humana.","Basándome en la información recuperada, ELIZA fue un programa informático desarrollado en los primeros años de la Inteligencia Artificial que logró simular una conversación terapéutica con un usuario. ELIZA fue creada por Joseph Weizenbaum en el MIT en la década de 1960 y se destacó por su capacidad para interactuar con los usuarios a través de un lenguaje natural, imitando el estilo de un psicoterapeuta.  En sus primeros años, ELIZA logró generar un impacto significativo en el campo de la Intel","doc_016_Constitucion_Colombia_2024.pdf",1,false,0.745,1,1,1,0,1,0.761,2025-11-23T23:01:09.646Z
Q049,ml_clasico,avanzado,"¿Por qué los métodos ensemble suelen mejorar el rendimiento de un modelo?","Combinan múltiples modelos base para reducir la varianza, el sesgo o ambos, produciendo predicciones más robustas. Técnicas como bagging y boosting permiten capturar distintos patrones del conjunto de datos.","Los métodos ensemble suelen mejorar el rendimiento de un modelo por varias razones:  1. **Reducción del sesgo y la varianza**: Al combinar múltiples modelos, se reduce el riesgo de sobreajuste (varianza alta) y subajuste (sesgo alto) que pueden presentarse en un solo modelo. Cada modelo en el ensemble puede compensar las debilidades de los otros, lo que lleva a una mejor generalización y rendimiento en datos nuevos.  2. **Mayor estabilidad y robustez**: Los ensembles son más estables y robustos ","",0,true,0.511,1,1,0.3,0.5,1,0.489,2025-11-23T23:01:09.646Z
Q050,deep_learning_llms,basico,"¿Qué es el descenso de gradiente en el entrenamiento de redes neuronales?","Es un método iterativo que ajusta los parámetros de un modelo minimizando una función de pérdida. Calcula gradientes para determinar la dirección en la que deben modificarse los pesos para mejorar el rendimiento.","El descenso de gradiente en el entrenamiento de redes neuronales es un concepto fundamental en el campo del aprendizaje automático. Consiste en un algoritmo utilizado para minimizar la función de pérdida durante el proceso de entrenamiento de una red neuronal.   En el contexto de la Inteligencia Artificial y el Deep Learning, el descenso de gradiente se utiliza para ajustar los pesos de la red neuronal de manera iterativa, con el objetivo de encontrar los valores óptimos que minimicen la función","doc_004_AI_Cognitive_Models.pdf, doc_007_PeerJ_AI_Applications.pdf",2,false,0.812,1,0.9,1,0,1,0.769,2025-11-23T23:01:09.647Z
Q051,conceptos_basicos,basico,"¿Qué es el preprocesamiento de datos en un proyecto de IA?","Es el conjunto de técnicas utilizadas para limpiar, transformar y preparar los datos antes de entrenar un modelo. Incluye normalización, eliminación de valores faltantes y codificación de variables.","El preprocesamiento de datos en un proyecto de Inteligencia Artificial es una etapa fundamental que implica la preparación y limpieza de los datos antes de utilizarlos en modelos de IA. En un estudio realizado en la Universidad de Caldas, se destaca la importancia de desarrollar habilidades digitales estratégicas para el uso de herramientas de IA en la formulación de proyectos de investigación formativa. Este proyecto de investigación cualitativa se enfoca en analizar, diseñar, evaluar y divulga","doc_006_Digital_Skills_AI_Tools.pdf, doc_004_AI_Cognitive_Models.pdf",2,false,0.685,1,1,1,0,1,0.74,2025-11-23T23:01:09.647Z
Q052,historia,intermedio,"¿Qué aportó el Perceptrón al desarrollo del aprendizaje automático?","Introdujo uno de los primeros modelos de redes neuronales capaces de aprender mediante ajuste de pesos. Aunque limitado, sentó las bases para el desarrollo de métodos más avanzados.","El Perceptrón, desarrollado por Frank Rosenblatt en 1957, fue un hito fundamental en el desarrollo del aprendizaje automático. Este modelo de red neuronal de una sola capa con capacidad de aprendizaje supervisado sentó las bases para futuros avances en el campo de la inteligencia artificial.  El Perceptrón introdujo el concepto de aprendizaje supervisado, donde el modelo es entrenado con ejemplos etiquetados para aprender a realizar clasificaciones. Su estructura simple de una sola capa de neuro","Processes_AI_Industrial.pdf, AI_Cognitive_Models.pdf",2,false,0.732,1,1,1,0,1,0.756,2025-11-23T23:01:09.647Z
Q053,ml_clasico,intermedio,"¿Qué es la validación cruzada y por qué se utiliza?","Es una técnica que divide los datos en varios subconjuntos para evaluar el desempeño del modelo de manera más robusta. Permite estimar mejor su capacidad de generalización.","La validación cruzada es una técnica utilizada en machine learning para evaluar el rendimiento de un modelo predictivo. Consiste en dividir el conjunto de datos en subconjuntos de entrenamiento y prueba de manera repetida, ajustando el modelo en los datos de entrenamiento y evaluando su desempeño en los datos de prueba. Esto se repite varias veces para obtener una estimación más precisa del rendimiento del modelo en datos no vistos.  La validación cruzada se utiliza para abordar el problema de l","",0,true,0.92,1,1,0.3,0.5,1,0.632,2025-11-23T23:01:09.647Z
Q054,deep_learning_llms,avanzado,"¿Qué función cumple la atención en los modelos tipo Transformer?","La atención permite que el modelo asigne importancia variable a diferentes partes de la secuencia de entrada. Esto mejora la captura de dependencias largas y la eficiencia del entrenamiento.","La atención en los modelos tipo Transformer, como los Vision Transformers (ViT), cumple una función crucial al permitir que la red se enfoque en diferentes partes de los datos de entrada y ajuste dinámicamente la importancia de cada característica. En el caso de los Vision Transformers, esta atención se logra a través de mecanismos de autoatención, lo que les permite aprender características directamente de los datos de entrada de manera dinámica. Esta capacidad de atención tiene varias ventajas","doc_007_PeerJ_AI_Applications.pdf, doc_004_AI_Cognitive_Models.pdf",2,false,0.525,1,1,1,0,1,0.684,2025-11-23T23:01:09.647Z
Q055,etica_regulacion,avanzado,"¿Qué riesgos presenta la toma de decisiones automatizada sin supervisión humana?","Puede generar decisiones opacas, sesgadas o difíciles de impugnar. La ausencia de supervisión reduce la capacidad de corregir errores y afecta la responsabilidad y transparencia.","La toma de decisiones automatizada sin supervisión humana presenta diversos riesgos que deben ser considerados:  1. **Riesgo de socavar la autonomía de las personas**: La implementación de sistemas basados en Inteligencia Artificial (IA) sin un desarrollo ético adecuado puede socavar la autonomía de las personas, limitando su capacidad de decisión y control sobre las acciones realizadas por los sistemas automatizados. Esto puede tener implicaciones negativas en la vida de las personas y en la so","Springer_AI_ML_Review.pdf, AI_Cognitive_Models.pdf",2,false,0.3,1,0.8,1,0,1,0.575,2025-11-23T23:01:09.648Z
Q056,aplicaciones,basico,"¿Cómo se emplea la IA en los sistemas de recomendación?","Utiliza algoritmos que analizan el comportamiento del usuario y patrones de consumo para sugerir contenido relevante. Incluye filtrado colaborativo y modelos basados en contenido.","En los sistemas de recomendación, la Inteligencia Artificial (IA) desempeña un papel fundamental al utilizar algoritmos y modelos para predecir y recomendar elementos de interés para los usuarios. Según un artículo titulado ""Aproximación desde la Inteligencia Artificial a los comportamientos poco predictivos derivados de modelos cognitivos artificiales"", se destaca que la IA se emplea para generar comportamientos interpretables por humanos en agentes inteligentes. La interpretabilidad se refie","doc_004_AI_Cognitive_Models.pdf",1,false,0.425,1,1,1,0,1,0.649,2025-11-23T23:01:09.648Z
Q057,conceptos_basicos,intermedio,"¿Qué es un modelo generativo?","Es un tipo de modelo que aprende la distribución de los datos para generar nuevas muestras similares a las originales. Incluye GANs, modelos autoregresivos y difusores.","Un modelo generativo es un tipo de modelo en el campo de la inteligencia artificial que se utiliza para generar datos nuevos que son similares a los datos de entrenamiento. Estos modelos son capaces de aprender la estructura y las características de un conjunto de datos para luego crear nuevas muestras que se asemejen a los datos originales.   En el contexto de la investigación académica sobre modelos cognitivos artificiales, se menciona el uso de la arquitectura cognitiva SOAR para el desarroll","doc_004_AI_Cognitive_Models.pdf",1,false,0.427,1,0.9,1,0,1,0.634,2025-11-23T23:01:09.648Z
Q058,historia,avanzado,"¿Qué impacto tuvo el 'AI Winter' en la investigación de inteligencia artificial?","Provocó una caída significativa en financiamiento y expectativas debido a resultados decepcionantes. Aun así, motivó líneas más realistas y sentó bases para avances posteriores.","Durante el periodo conocido como el 'AI Winter', la investigación en inteligencia artificial experimentó un impacto significativo. A pesar de que la IA había mostrado avances prometedores en sus inicios, factores como la falta de avances prácticos, la sobreexpectación y la falta de financiamiento llevaron a una disminución en la inversión y el interés en esta área. Este fenómeno resultó en un estancamiento en la investigación y el desarrollo de la inteligencia artificial durante ese período.  El","",0,true,0.53,1,1,0.3,0.5,1,0.495,2025-11-23T23:01:09.648Z
Q059,ml_clasico,basico,"¿Qué diferencia hay entre clasificación y regresión?","La clasificación predice categorías discretas, mientras que la regresión estima valores numéricos continuos. Representan dos tipos fundamentales de tareas supervisadas.","La diferencia fundamental entre clasificación y regresión radica en el tipo de variable que se intenta predecir o modelar:  - **Clasificación**: En la clasificación, el objetivo es predecir la pertenencia de un elemento a una categoría o clase específica. Se trata de un problema de aprendizaje supervisado donde el modelo asigna una etiqueta a cada instancia de entrada. Por ejemplo, en un problema de clasificación de correos electrónicos como ""spam"" o ""no spam"", el modelo clasificará cada cor","",0,true,0.813,1,1,0.3,0.5,1,0.595,2025-11-23T23:01:09.648Z
Q060,deep_learning_llms,intermedio,"¿Qué es el fine-tuning en modelos de lenguaje?","Es el proceso de ajustar un modelo preentrenado sobre un conjunto de datos específico para adaptarlo a una tarea concreta. Permite obtener buen desempeño con menos datos y tiempo de entrenamiento.","El fine-tuning en modelos de lenguaje se refiere a la técnica de ajustar un modelo preentrenado para adaptarlo a una tarea específica o a un conjunto de datos particulares. Esta técnica es comúnmente utilizada en el campo del procesamiento del lenguaje natural para mejorar el rendimiento de los modelos en tareas específicas, como la clasificación de texto, la generación de texto o la traducción automática.  El proceso de fine-tuning implica tomar un modelo preentrenado, que ha aprendido represen","doc_004_AI_Cognitive_Models.pdf",1,false,0.589,1,1,1,0,1,0.706,2025-11-23T23:01:09.648Z


--- RESUMEN GLOBAL ---
Total Preguntas,60
Modelo,gpt-3.5-turbo
Score Global,0.645
Tasa Alucinacion %,11.3
Porcentaje Con Citas,78.33
IFA,0.721
Aprobado,false
